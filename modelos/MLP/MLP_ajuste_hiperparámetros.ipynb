{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef17995",
   "metadata": {},
   "source": [
    "# Modelo Perceptrón Multicapa\n",
    "[MLP - Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1ddf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f70f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos la carpeta 'drive' al path\n",
    "ruta_carpeta_drive = os.path.abspath('../../drive')\n",
    "if ruta_carpeta_drive not in sys.path:\n",
    "    sys.path.insert(0, ruta_carpeta_drive)\n",
    "\n",
    "import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777f790",
   "metadata": {},
   "source": [
    "Para entrenar este modelo hemos partido del conjunto de datos ya limpio con la variable GenresList transformada con OneHotEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36676a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo datosEntrenamiento.parquet guardado en: ../data/clean/datosEntrenamiento.parquet\n"
     ]
    }
   ],
   "source": [
    "# Descargamos los datos en formato parquet de Google Drive\n",
    "drive.descargar_archivos_concretos('datosEntrenamiento.parquet', '../../drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce54e302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_parquet('../data/clean/datosEntrenamiento.parquet')\n",
    "data = pd.read_csv('/Users/maria/Downloads/ENTRENAMIENTO_FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2a2675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Bestseller</th>\n",
       "      <th>NumPages</th>\n",
       "      <th>SagaNumber</th>\n",
       "      <th>RedPerc</th>\n",
       "      <th>BluePerc</th>\n",
       "      <th>BelongsSaga</th>\n",
       "      <th>Price</th>\n",
       "      <th>WordsTitle</th>\n",
       "      <th>PriceFormat</th>\n",
       "      <th>...</th>\n",
       "      <th>Womens</th>\n",
       "      <th>Womens Fiction</th>\n",
       "      <th>World War I</th>\n",
       "      <th>World War II</th>\n",
       "      <th>Young Adult</th>\n",
       "      <th>Young Adult Contemporary</th>\n",
       "      <th>Young Adult Fantasy</th>\n",
       "      <th>Young Adult Romance</th>\n",
       "      <th>Young Adult Science Fiction</th>\n",
       "      <th>Zombies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ebook</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2335.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1</td>\n",
       "      <td>20.99</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ebook</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hardcover</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>paperback</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Bestseller  NumPages  SagaNumber  RedPerc  BluePerc  \\\n",
       "0           0         0.0     329.0         1.0     0.51      0.40   \n",
       "1           1         0.0     269.0         2.0     0.61      0.54   \n",
       "2           2         0.0    2335.0         1.0     0.72      0.57   \n",
       "3           3         0.0      40.0         1.0     0.83      0.35   \n",
       "4           4         0.0     189.0         1.0     0.59      0.26   \n",
       "\n",
       "   BelongsSaga  Price  WordsTitle PriceFormat  ...  Womens  Womens Fiction  \\\n",
       "0            0  19.99         1.0   paperback  ...       0               0   \n",
       "1            1   3.99         2.0       ebook  ...       0               0   \n",
       "2            1  20.99         7.0       ebook  ...       0               0   \n",
       "3            0  25.00         1.0   hardcover  ...       0               0   \n",
       "4            0  15.00         4.0   paperback  ...       0               0   \n",
       "\n",
       "   World War I  World War II  Young Adult  Young Adult Contemporary  \\\n",
       "0            0             0            0                         0   \n",
       "1            0             0            0                         0   \n",
       "2            0             0            1                         0   \n",
       "3            0             0            1                         0   \n",
       "4            0             0            0                         0   \n",
       "\n",
       "   Young Adult Fantasy  Young Adult Romance  Young Adult Science Fiction  \\\n",
       "0                    0                    0                            0   \n",
       "1                    0                    0                            0   \n",
       "2                    0                    0                            0   \n",
       "3                    0                    0                            0   \n",
       "4                    0                    0                            0   \n",
       "\n",
       "   Zombies  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0c6c0",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e2c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold, cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b4b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla\n",
    "SEED = 22\n",
    "\n",
    "# Proporción del conjunto de test\n",
    "TEST_SIZE = 0.3\n",
    "\n",
    "# Número de folds para la validación cruzada\n",
    "CV_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edf1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codificarPriceFormat(df):\n",
    "    return pd.get_dummies(df, columns=['PriceFormat'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fe008",
   "metadata": {},
   "source": [
    "### Métricas de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5c2b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e185fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la sensibilidad\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "# Función para calcular la especificidad\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# Convertir las funciones en funciones de puntuación\n",
    "sensitivity_scorer = make_scorer(sensitivity)\n",
    "specificity_scorer = make_scorer(specificity)\n",
    "\n",
    "METRICS = {'balanced_accuracy': 'balanced_accuracy',\n",
    "           'sensitivity': sensitivity_scorer,\n",
    "           'specificity': specificity_scorer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f2524",
   "metadata": {},
   "source": [
    "### Preparamos entorno de Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6acc65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8bde57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/28 01:33:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/04/28 01:33:13 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2024/04/28 01:33:13 INFO mlflow.tracking.fluent: Experiment with name 'MultiLayerPerceptron' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/maria/Dropbox/UCM/PD1/NOVELLA/modelos/MLP/mlruns/1', creation_time=1714260793743, experiment_id='1', last_update_time=1714260793743, lifecycle_stage='active', name='MultiLayerPerceptron', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets the sqlite db as the MLFLOW_TRACKING_URI \n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'sqlite:///mlruns.db'\n",
    "\n",
    "# WARNING: TO SEE THE LOCAL SERVER YOU HAVE TO CHOOSE THE CORRECT BACKEND STORE AS FOLLOWS:\n",
    "# mlflow ui --port 8080 --backend-store-uri sqlite:///mlruns.db\n",
    "\n",
    "\n",
    "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Para imprimir los experimentos que están en la base de datos\n",
    "\n",
    "# Establecer la URI de seguimiento\n",
    "mlflow.set_tracking_uri('sqlite:///mlruns.db')\n",
    "\n",
    "# Obtener todos los experimentos\n",
    "experiment_ids = mlflow.search_runs().experiment_id.unique()\n",
    "\n",
    "# Imprimir los experimentos\n",
    "for exp_id in experiment_ids:\n",
    "    print(exp_id)\n",
    "    \n",
    "# Defino el experimento el que guardaré todas las ejecuciones\n",
    "mlflow.set_experiment(experiment_name = 'MultiLayerPerceptron')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956d5e0",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Creamos un modelo base para después comparar con los otros modelos que entrenemos con más técnicas de procesado y transformaciones. \n",
    "\n",
    "Modelo baseline:\n",
    "* Parámetros por defecto\n",
    "* Todas las variables\n",
    "* Sin transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d208370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c299479",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBaseline = data.copy()\n",
    "dataBaseline = codificarPriceFormat(dataBaseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208d2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_base = dataBaseline.drop('Bestseller', axis=1)\n",
    "y_base = dataBaseline['Bestseller']\n",
    "X_base_train, X_base_test, y_base_train, y_base_test = train_test_split(X_base, y_base, test_size=TEST_SIZE, stratify=y_base, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acced820",
   "metadata": {},
   "outputs": [],
   "source": [
    "PMC = sklearn.neural_network.MLPClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96787255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.1s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(PMC, X_base_train, y_base_train, scoring=METRICS, cv=CV_FOLDS,\n",
    "                        return_train_score=True, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae55911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([2.12465405, 2.20799708, 2.63712096, 1.62038493, 2.06694722]),\n",
       " 'score_time': array([0.01559711, 0.01360488, 0.01043105, 0.01252508, 0.01790786]),\n",
       " 'test_balanced_accuracy': array([0.7215262 , 0.80168833, 0.7453437 , 0.62438028, 0.76547785]),\n",
       " 'train_balanced_accuracy': array([0.80677319, 0.86733939, 0.85503997, 0.64617779, 0.83764488]),\n",
       " 'test_sensitivity': array([0.5       , 0.70588235, 0.52941176, 0.26470588, 0.59701493]),\n",
       " 'train_sensitivity': array([0.65682657, 0.80073801, 0.74538745, 0.29520295, 0.72426471]),\n",
       " 'test_specificity': array([0.94305239, 0.89749431, 0.96127563, 0.98405467, 0.93394077]),\n",
       " 'train_specificity': array([0.95671982, 0.93394077, 0.96469248, 0.99715262, 0.95102506])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7454cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2024/04/28 01:34:24 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"82bdcfa802584309bc025c34e20b7442\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22280 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Successfully registered model 'baseline'.\n",
      "Created version '1' of model 'baseline'.\n"
     ]
    }
   ],
   "source": [
    "# Registramos los resultados en MlFlow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    for metric in METRICS.keys():\n",
    "        # Calculate the mean values for train and test sets\n",
    "        train_mean = np.mean(scores[f\"train_{metric}\"])\n",
    "        test_mean = np.mean(scores[f\"test_{metric}\"])\n",
    "\n",
    "        # Log the mean values for train and test sets\n",
    "        mlflow.log_metric(f\"train_{metric}_mean\", train_mean)\n",
    "        mlflow.log_metric(f\"test_{metric}_mean\", test_mean)\n",
    "\n",
    "    # Establece una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"Baseline (default) sinfic\")\n",
    "\n",
    "    # Infiere el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    PMC.fit(X_base_train, y_base_train)\n",
    "    signature = infer_signature(X_base_train, PMC.predict(X_base_train))\n",
    "\n",
    "    # Registra el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=PMC,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_base_train,\n",
    "        registered_model_name=\"baseline\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6846854e",
   "metadata": {},
   "source": [
    "### Escalado de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72117094",
   "metadata": {},
   "source": [
    "Para mejorar el rendimiento de la red neuronal, vamos a escalar las variables. Como los datos tienen muchos outliers, una estandarización sería muy susceptible a valores extremos. Por lo tanto, vamos a aplicar un [escalado robusto](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#plot-all-scaling-robust-scaler-section), que usa la mediana y los rangos intercuartílicos. De esta forma la transformación será más resistente a las variaciones introducidas por datos atípicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233239e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34201d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = data.copy()\n",
    "X_scaled = data_scaled.drop('Bestseller', axis=1)\n",
    "y_scaled = data_scaled['Bestseller']\n",
    "\n",
    "# Dividimos en train y test\n",
    "X_scaled_train, X_scaled_test, y_scaled_train, y_scaled_test = train_test_split(X_scaled, y_scaled, test_size=TEST_SIZE, stratify=y_scaled, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a335e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Solo lo aplicamos a las variables numéricas\n",
    "# Incluimos 'Zombies' que no hay que escalar porque el RobustScaler ignora la primera columna de la lista \n",
    "# (hemos hecho pruebas)\n",
    "variables_numericas = ['Zombies', 'SagaNumber', 'NumPages', 'RedPerc', 'BluePerc', 'Price', 'WordsTitle', 'BookInterest1M',\n",
    "                     'Rating20Days', 'PrevBestSellAuthor']\n",
    "\n",
    "# Aplicamos el RobustScaler a los datos de entrenamiento y test\n",
    "X_scaled_train[variables_numericas] = scaler.fit_transform(X_scaled_train[variables_numericas])\n",
    "X_scaled_test[variables_numericas] = scaler.transform(X_scaled_test[variables_numericas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eae73f",
   "metadata": {},
   "source": [
    "### Transformación de variables para el entrenamiento\n",
    "\n",
    "Vamos a transformar la columna 'PriceFormat' con variables dummy para poder entrenar los modelos después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb5e2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_train = X_scaled_train.copy()\n",
    "X_to_train = codificarPriceFormat(X_to_train)\n",
    "\n",
    "X_to_test = X_scaled_test.copy()\n",
    "X_to_test = codificarPriceFormat(X_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4218a4",
   "metadata": {},
   "source": [
    "### Creación de KFolds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ee0bb",
   "metadata": {},
   "source": [
    "Estrategia de [validación cruzada](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) con k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78543c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afcc402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el objeto KFold\n",
    "kf = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c695c69",
   "metadata": {},
   "source": [
    "### Creación del pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b17032f",
   "metadata": {},
   "source": [
    "Creamos un pipeline con las operaciones que se deben aplicar a cada fold en el entrenamiento:\n",
    "* Oversampling (SMOTENC)\n",
    "* Redondear variables enteras\n",
    "* Transformación variables categóricas con un valor único\n",
    "* Clasificador (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f162b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79162eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redondearVariables(X):\n",
    "    variablesRedondeo = [\"NumPages\", \"SagaNumber\", \"WordsTitle\"]\n",
    "    # Itera sobre las columnas especificadas y redondea sus valores\n",
    "    for v in variablesRedondeo:\n",
    "        X[v] = np.round(X[v])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbd03555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas de los géneros\n",
    "columnas_generos = X_scaled_train.columns[14:]\n",
    "\n",
    "# Columnas categóricas\n",
    "categoricalColumns = [\"BelongsSaga\", \"PriceFormat\", 'HasTwitter', 'HasWikipedia'] + list(columnas_generos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e383d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTENC(categorical_features = categoricalColumns, random_state = SEED)\n",
    "\n",
    "# Definimos el clasificador \n",
    "PMC = sklearn.neural_network.MLPClassifier(random_state=SEED)\n",
    "\n",
    "# Definimos el transformador para codificar la variable categórica 'PriceFormat'\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['PriceFormat'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Definimos el transformador de la función para redondear\n",
    "transformador_funcion = FunctionTransformer(func=redondearVariables)\n",
    "\n",
    "# Construimos el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('smote', smote),\n",
    "    ('redondear_variables', transformador_funcion),\n",
    "    ('encoder', column_transformer),\n",
    "    ('classifier', PMC)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d095ef",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee92221",
   "metadata": {},
   "source": [
    "Vamos a buscar los hiperparámetros que optimicen el modelo probando una serie de combinaciones. Para ello, vamos a usar:\n",
    "* Datos con escalado robusto\n",
    "* Pipeline previamente creado\n",
    "* Cross validation con k folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdb80d",
   "metadata": {},
   "source": [
    "Como las redes neuronales son muy costosas computacionalmente, vamos a dividir el ajuste de hiperparámetros en tres pasos.  Los dos primeros reducen mucho el número de opciones y por lo tanto optimizan el tiempo de ejecución.\n",
    "\n",
    "1. Elegir la arquitectura más óptima de una serie de opciones mediante cross-validation con k folds\n",
    "2. Ajustar el resto de hiperparámetros mediante GridSearch y RandomSearch tras fijar dicha arquitectura (para reducir el tiempo de entrenamiento)\n",
    "3. Ajustar todos los hiperparámetros a la vez (incluida la arquitectura) mediante GridSearch y RandomSearch\n",
    "\n",
    "Además, vamos a fijar la función de activación a 'logistic', que es la indicada para cuando la salida es una probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6fcf",
   "metadata": {},
   "source": [
    "### 1. Ajuste de la arquitectura de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed316b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   18.8s remaining:   28.2s\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   23.7s remaining:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   28.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   18.9s remaining:   28.4s\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/maria/anaconda3/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   23.6s remaining:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   29.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   27.0s remaining:   40.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   36.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   34.0s remaining:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   40.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   27.4s remaining:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   35.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   20.2s remaining:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.6s remaining:   29.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   24.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Definimos varias opciones para la distribución de las capas de neuronas\n",
    "layers = [(50,), (100,), (50, 50), (100, 100), (200,), (150, 150), (200, 100), (100, 50, 25), (150, 100, 50)]\n",
    "\n",
    "# Inicializamos la lista de scores\n",
    "scores = {}\n",
    "\n",
    "# Iterate over the list of hidden layer sizes\n",
    "for hidden_layer_sizes in layers:\n",
    "    # Set parameters for the neural network model inside the pipeline\n",
    "    params = {'classifier__hidden_layer_sizes': hidden_layer_sizes,\n",
    "              'classifier__activation':'logistic'}\n",
    "    pipeline.set_params(**params)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(estimator=pipeline, X=X_scaled_train, y=y_scaled_train,\n",
    "                                scoring=METRICS, cv=kf, return_train_score=True,\n",
    "                                verbose=1, n_jobs=-1)\n",
    "    \n",
    "    # Append the results to the scores list\n",
    "    scores[hidden_layer_sizes] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0af376d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(50,): {'fit_time': array([17.40849566, 18.16318011, 18.53774595, 18.47975612, 16.69785213]),\n",
       "  'score_time': array([0.01240444, 0.0077281 , 0.01255512, 0.01318693, 0.01522684]),\n",
       "  'test_balanced_accuracy': array([0.80137009, 0.78780316, 0.78034973, 0.77185783, 0.7666168 ]),\n",
       "  'train_balanced_accuracy': array([0.82426725, 0.83307101, 0.86157739, 0.87290912, 0.87018876]),\n",
       "  'test_sensitivity': array([0.63235294, 0.60294118, 0.61764706, 0.60294118, 0.59701493]),\n",
       "  'train_sensitivity': array([0.66789668, 0.68265683, 0.75276753, 0.7896679 , 0.78308824]),\n",
       "  'test_specificity': array([0.97038724, 0.97266515, 0.94305239, 0.94077449, 0.93621868]),\n",
       "  'train_specificity': array([0.98063781, 0.98348519, 0.97038724, 0.95615034, 0.95728929])},\n",
       " (100,): {'fit_time': array([23.30723691, 27.57325792, 27.90124202, 23.18618703, 23.87523794]),\n",
       "  'score_time': array([0.01989293, 0.01733994, 0.01404285, 0.02275014, 0.01669717]),\n",
       "  'test_balanced_accuracy': array([0.81535576, 0.77309728, 0.76512461, 0.78988008, 0.71767586]),\n",
       "  'train_balanced_accuracy': array([0.85657713, 0.83803659, 0.84144189, 0.87330733, 0.82234021]),\n",
       "  'test_sensitivity': array([0.70588235, 0.57352941, 0.57352941, 0.66176471, 0.46268657]),\n",
       "  'train_sensitivity': array([0.76383764, 0.69372694, 0.70110701, 0.80811808, 0.66176471]),\n",
       "  'test_specificity': array([0.92482916, 0.97266515, 0.95671982, 0.91799544, 0.97266515]),\n",
       "  'train_specificity': array([0.94931663, 0.98234624, 0.98177677, 0.93849658, 0.98291572])},\n",
       " (50,\n",
       "  50): {'fit_time': array([22.71448493, 18.85564184, 20.57743907, 16.92100692, 23.46649194]), 'score_time': array([0.01166105, 0.01668096, 0.01605487, 0.02311587, 0.01522517]), 'test_balanced_accuracy': array([0.77237706, 0.79743401, 0.81483653, 0.74876055, 0.76245198]), 'train_balanced_accuracy': array([0.90770285, 0.85464176, 0.89065324, 0.83292286, 0.86109808]), 'test_sensitivity': array([0.61764706, 0.61764706, 0.69117647, 0.52941176, 0.55223881]), 'train_sensitivity': array([0.84501845, 0.72693727, 0.82287823, 0.68634686, 0.73529412]), 'test_specificity': array([0.92710706, 0.97722096, 0.93849658, 0.96810934, 0.97266515]), 'train_specificity': array([0.97038724, 0.98234624, 0.95842825, 0.97949886, 0.98690205])},\n",
       " (100,\n",
       "  100): {'fit_time': array([29.14654994, 21.06157207, 29.28409982, 23.46428275, 27.58156228]), 'score_time': array([0.01507306, 0.02480578, 0.01603103, 0.02149987, 0.01890373]), 'test_balanced_accuracy': array([0.83731408, 0.82892269, 0.7498995 , 0.75383559, 0.76245198]), 'train_balanced_accuracy': array([0.89872782, 0.87670107, 0.81619266, 0.8569081 , 0.86192717]), 'test_sensitivity': array([0.77941176, 0.73529412, 0.52941176, 0.54411765, 0.55223881]), 'train_sensitivity': array([0.84870849, 0.82287823, 0.64206642, 0.73431734, 0.74264706]), 'test_specificity': array([0.8952164 , 0.92255125, 0.97038724, 0.96355353, 0.97266515]), 'train_specificity': array([0.94874715, 0.93052392, 0.99031891, 0.97949886, 0.98120729])},\n",
       " (200,): {'fit_time': array([36.50870395, 29.79641914, 24.56570005, 28.02017617, 26.88105989]),\n",
       "  'score_time': array([0.02357626, 0.01918387, 0.0229907 , 0.01711583, 0.0220542 ]),\n",
       "  'test_balanced_accuracy': array([0.80188932, 0.81825338, 0.81649471, 0.79391666, 0.75687621]),\n",
       "  'train_balanced_accuracy': array([0.86982323, 0.86681615, 0.86052879, 0.86609852, 0.8666421 ]),\n",
       "  'test_sensitivity': array([0.64705882, 0.69117647, 0.70588235, 0.64705882, 0.58208955]),\n",
       "  'train_sensitivity': array([0.7601476 , 0.77121771, 0.78597786, 0.77490775, 0.77941176]),\n",
       "  'test_specificity': array([0.95671982, 0.9453303 , 0.92710706, 0.94077449, 0.93166287]),\n",
       "  'train_specificity': array([0.97949886, 0.96241458, 0.93507973, 0.95728929, 0.95387244])},\n",
       " (150,\n",
       "  150): {'fit_time': array([36.92998409, 33.8909719 , 36.56449723, 40.70947981, 23.34174275]), 'score_time': array([0.018085  , 0.01960611, 0.04943395, 0.01428604, 0.02328706]), 'test_balanced_accuracy': array([0.85979164, 0.80137009, 0.80644513, 0.8143173 , 0.76724578]), 'train_balanced_accuracy': array([0.91126575, 0.88443523, 0.87679353, 0.90827232, 0.87992429]), 'test_sensitivity': array([0.86764706, 0.63235294, 0.64705882, 0.67647059, 0.6119403 ]), 'train_sensitivity': array([0.93357934, 0.79335793, 0.76383764, 0.84501845, 0.80882353]), 'test_specificity': array([0.85193622, 0.97038724, 0.96583144, 0.95216401, 0.92255125]), 'train_specificity': array([0.88895216, 0.97551253, 0.98974943, 0.9715262 , 0.95102506])},\n",
       " (200,\n",
       "  100): {'fit_time': array([32.6684289 , 25.35761929, 27.24080896, 34.9083221 , 29.84733009]), 'score_time': array([0.01854706, 0.02953982, 0.02531815, 0.0150547 , 0.02168512]), 'test_balanced_accuracy': array([0.80986199, 0.77765309, 0.79401715, 0.79837197, 0.75852514]), 'train_balanced_accuracy': array([0.86586001, 0.82370933, 0.83095281, 0.91192769, 0.87730722]), 'test_sensitivity': array([0.64705882, 0.57352941, 0.61764706, 0.67647059, 0.56716418]), 'train_sensitivity': array([0.74538745, 0.66051661, 0.67158672, 0.87453875, 0.78308824]), 'test_specificity': array([0.97266515, 0.98177677, 0.97038724, 0.92027335, 0.9498861 ]), 'train_specificity': array([0.98633257, 0.98690205, 0.99031891, 0.94931663, 0.9715262 ])},\n",
       " (100,\n",
       "  50,\n",
       "  25): {'fit_time': array([18.03143811, 20.07785106, 20.89346504, 20.18200493, 20.96618271]), 'score_time': array([0.01519299, 0.01462698, 0.01068497, 0.01439881, 0.01091528]), 'test_balanced_accuracy': array([0.79557484, 0.81607597, 0.80530618, 0.78604449, 0.77875429]), 'train_balanced_accuracy': array([0.88469685, 0.88713446, 0.87536984, 0.89564193, 0.91360713]), 'test_sensitivity': array([0.66176471, 0.66176471, 0.64705882, 0.61764706, 0.64179104]), 'train_sensitivity': array([0.80811808, 0.79704797, 0.76383764, 0.81918819, 0.86764706]), 'test_specificity': array([0.92938497, 0.97038724, 0.96355353, 0.95444191, 0.91571754]), 'train_specificity': array([0.96127563, 0.97722096, 0.98690205, 0.97209567, 0.9595672 ])},\n",
       " (150,\n",
       "  100,\n",
       "  50): {'fit_time': array([19.86844802, 23.02436423, 24.25759602, 19.48614097, 17.6415801 ]), 'score_time': array([0.01910996, 0.01292181, 0.01091909, 0.01770902, 0.02018881]), 'test_balanced_accuracy': array([0.86340949, 0.79629506, 0.80748359, 0.77423623, 0.80671812]), 'train_balanced_accuracy': array([0.91165451, 0.87934462, 0.90459384, 0.88374072, 0.89372153]), 'test_sensitivity': array([0.80882353, 0.61764706, 0.67647059, 0.57352941, 0.65671642]), 'train_sensitivity': array([0.86715867, 0.77121771, 0.8302583 , 0.78228782, 0.8125    ]), 'test_specificity': array([0.91799544, 0.97494305, 0.93849658, 0.97494305, 0.95671982]), 'train_specificity': array([0.95615034, 0.98747153, 0.97892938, 0.98519362, 0.97494305])}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6603e9e",
   "metadata": {},
   "source": [
    "Estudiamos las gráficas de las métricas para cada distribución de las capas para elegir la óptima y poder ajustar el resto de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1be00375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "for i, metric in enumerate(METRICS.keys()):\n",
    "    # Initialize lists to store mean scores\n",
    "    train_means = []\n",
    "    test_means = []\n",
    "    \n",
    "    # Recorremos las capas\n",
    "    for layer in layers:\n",
    "        # Calculamos la media de esa métrica de entrenamiento y test\n",
    "        train_mean = np.mean(scores[layer][f\"train_{metric}\"])\n",
    "        test_mean = np.mean(scores[layer][f\"test_{metric}\"])\n",
    "\n",
    "        # Append to lists\n",
    "        train_means.append(train_mean)\n",
    "        test_means.append(test_mean)\n",
    "    \n",
    "    # Mostramos las métricas en la gráfica\n",
    "    axes[i].bar(range(len(layers)), train_means, label='Train')\n",
    "    axes[i].bar(range(len(layers)), test_means, label='Test')\n",
    "    \n",
    "    # Set labels and title\n",
    "    axes[i].set_xlabel('Layers')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].set_title(f'Mean {metric} for Different Layer Configurations')\n",
    "    \n",
    "    # Set xticks\n",
    "    axes[i].set_xticks(range(len(layers)))\n",
    "    axes[i].set_xticklabels(layers)\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    axes[i].set_ylim(0.5, 1)\n",
    "        \n",
    "    # Add legend\n",
    "    axes[i].legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd1235",
   "metadata": {},
   "source": [
    "Estudiando las gráficas, observamos que tanto para balanced_accuracy como para sensitivity el valor de la métrica en el test encuentra su máximo en una distribución de (150, 150).\n",
    "Aunque no es el caso para specificity (que se maximiza en (200, 100)), consigue un valor muy alto de 0.9.\n",
    "\n",
    "Por lo tanto, elegimos la estructura (150, 150) apoyándonos en las dos primeras métricas para continuar ajustando los hiperparámetros en el siguiente paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f10efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b349fe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/04/28 01:46:48 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"21c6d3c4468d4b889782632a0bae11aa\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22282 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Successfully registered model 'ajuste_capas'.\n",
      "Created version '1' of model 'ajuste_capas'.\n"
     ]
    }
   ],
   "source": [
    "# Registramos los resultados en MlFlow del modelo con la mejor distribución de capas de neuronas\n",
    "best_scores = scores[LAYERS]\n",
    "best_params = {'classifier__hidden_layer_sizes': LAYERS,\n",
    "              'classifier__activation':'logistic'}\n",
    "\n",
    "# Como hemos usado cross validation esta vez, tenemos que crear un nuevo modelo con los parametros deseados\n",
    "best_model = MLPClassifier(hidden_layer_sizes=LAYERS,\n",
    "                           activation='logistic')\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Calculamos la media de las métricas del mejor parámetro y las almacenamos\n",
    "    for metric in METRICS.keys():\n",
    "        # Calculate the mean values for train and test sets\n",
    "        train_mean = np.mean(best_scores[f\"train_{metric}\"])\n",
    "        test_mean = np.mean(best_scores[f\"test_{metric}\"])\n",
    "        \n",
    "        # Calculate the standard deviations for train and test sets\n",
    "        train_std = np.std(best_scores[f\"train_{metric}\"])\n",
    "        test_std = np.std(best_scores[f\"test_{metric}\"])\n",
    "\n",
    "        # Log the standard deviations for train and test sets\n",
    "        mlflow.log_metric(f\"train_{metric}_std\", train_std)\n",
    "        mlflow.log_metric(f\"test_{metric}_std\", test_std)\n",
    "\n",
    "        # Log the mean values for train and test sets\n",
    "        mlflow.log_metric(f\"train_{metric}_mean\", train_mean)\n",
    "        mlflow.log_metric(f\"test_{metric}_mean\", test_mean)\n",
    "    \n",
    "    # Almacenamos los valores de los hiperparámetros\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # Establecemos una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"Ajuste capas neuronas. Con dataset escalado. sinfic\")\n",
    "\n",
    "    # Inferimos el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    best_model.fit(X_to_train, y_scaled_train) # en este caso le metemos el df con las dummies de PriceFormat porque el modelo no tiene pipeline porque es el básico\n",
    "    signature = infer_signature(X_to_train, best_model.predict(X_to_train))\n",
    "\n",
    "    # Registramos el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=best_model,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_to_train,\n",
    "        registered_model_name=\"ajuste_capas\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58390595",
   "metadata": {},
   "source": [
    "### 2. Ajuste hiperparámetros adicionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33d622",
   "metadata": {},
   "source": [
    "Vamos a determinar algunos parámetros por defecto para mejorar la eficiencia del modelo:\n",
    "* **hidden_layer_sizes:** (150, 150) - obtenidos del experimento anterior\n",
    "* **activation:** 'logistic' - la salida es una probabilidad\n",
    "* **early_stopping:** True - detiene el entrenamiento de modelos cuando métricas que no mejoran\n",
    "* **solver:** 'adam' - método por defecto. Optimiza el descenso de gradiente estocástico y se recomienda para datasets grandes (más de mil filas de entrenamiento)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e12125",
   "metadata": {},
   "source": [
    "### 2.1 Grid Search\n",
    "[GridSearchCV - Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b73e009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    }
   ],
   "source": [
    "# Definir los hiperparámetros a ajustar\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [LAYERS],\n",
    "    'classifier__activation': ['logistic'],\n",
    "    'classifier__early_stopping': [True],\n",
    "    'classifier__alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'classifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'classifier__learning_rate_init': [0.0001, 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Inicializo GridSearch\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=kf,\n",
    "                           scoring=METRICS, return_train_score=True,\n",
    "                           refit='balanced_accuracy',\n",
    "                           verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "# Resultados\n",
    "cv_results_gr = grid_search.cv_results_\n",
    "best_params_gr = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5c458cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([26.58535099, 20.81975527, 16.73834453, 16.22915306, 28.71924982,\n",
       "        23.27891254, 17.61371193, 17.07552438, 29.71699762, 24.43355622,\n",
       "        20.15509405, 17.56349177, 30.05197906, 23.08750253, 15.49260077,\n",
       "        16.27141461, 29.70796523, 24.01458702, 16.58465452, 16.89647408,\n",
       "        28.71956367, 23.90972395, 17.93828502, 18.87385802, 31.94563885,\n",
       "        22.18046417, 14.72843003, 14.18119569, 25.86397991, 19.71019163,\n",
       "        14.48148184, 14.02736154, 26.02012811, 19.15739579, 14.25854549,\n",
       "        13.52567315, 25.96100802, 20.54489799, 14.65315213, 13.29056478,\n",
       "        24.97704878, 19.50639124, 14.53495741, 13.22225375, 24.67643604,\n",
       "        18.93479853, 13.81377254, 12.72247515, 24.9162641 , 17.81710796,\n",
       "        13.58913803, 12.43583031, 25.13552804, 18.18371925, 13.93668904,\n",
       "        12.84802284, 25.10255508, 18.75367365, 14.55774455, 12.44847221,\n",
       "        25.94220843, 18.14082541, 13.44458442, 12.81763597, 25.88463221,\n",
       "        18.26404362, 13.71867533, 12.94253154, 26.22860584, 18.46808186,\n",
       "        13.71831059, 12.95443583, 27.09629402, 21.09071345, 17.45407515,\n",
       "        16.91716218, 30.61854596, 22.34359975, 17.40914035, 15.96501617,\n",
       "        28.97764459, 21.04313407, 16.2903688 , 13.04911942]),\n",
       " 'std_fit_time': array([1.09532666, 2.46950901, 0.64548044, 0.39578971, 0.93691725,\n",
       "        2.27177067, 0.59422172, 0.32902337, 1.58874981, 2.51943518,\n",
       "        0.67574703, 0.57231733, 0.86737275, 1.35804309, 0.25215194,\n",
       "        1.17120397, 1.51419677, 1.16802593, 0.53319553, 1.16750588,\n",
       "        1.57231941, 2.0739311 , 0.36418987, 1.35505404, 2.60154532,\n",
       "        2.40202593, 0.87451238, 0.69794453, 3.14611306, 1.40196049,\n",
       "        0.95509551, 0.65506272, 3.00258406, 1.2866106 , 0.81145835,\n",
       "        0.67812203, 3.89935691, 2.05667735, 0.85306378, 0.51388747,\n",
       "        3.84062814, 2.17115067, 0.73743165, 0.53016693, 3.81693336,\n",
       "        1.88090287, 0.64844381, 0.68943218, 3.69571486, 0.43458099,\n",
       "        0.82639008, 0.18037928, 3.57922374, 0.33878588, 0.84975347,\n",
       "        0.18787933, 4.28449974, 1.06638449, 0.77186676, 0.30258943,\n",
       "        2.38926886, 1.5088968 , 0.73930457, 1.02253712, 2.2446869 ,\n",
       "        1.56503983, 0.83268965, 0.81328024, 2.18128987, 1.73346143,\n",
       "        0.85165608, 0.91524634, 1.84584848, 1.4879078 , 1.39633518,\n",
       "        0.93306509, 2.13868477, 1.59129555, 1.32668232, 0.93812597,\n",
       "        2.12345914, 2.05942382, 1.31459052, 0.44702405]),\n",
       " 'mean_score_time': array([0.04040699, 0.02554512, 0.03572469, 0.02407956, 0.0361846 ,\n",
       "        0.02706819, 0.02862201, 0.02117386, 0.03411641, 0.03812952,\n",
       "        0.03209915, 0.03330278, 0.03075299, 0.02287359, 0.02425036,\n",
       "        0.02759123, 0.03630605, 0.02871704, 0.02484064, 0.02737513,\n",
       "        0.02855282, 0.03411489, 0.02849684, 0.04521613, 0.02865181,\n",
       "        0.02132087, 0.02337151, 0.02015615, 0.02229338, 0.02469101,\n",
       "        0.0200336 , 0.02027807, 0.02845907, 0.02230058, 0.02157149,\n",
       "        0.02008462, 0.02875304, 0.02310753, 0.02024193, 0.01970243,\n",
       "        0.02080526, 0.02107158, 0.02882738, 0.02203765, 0.01995192,\n",
       "        0.02130966, 0.02019448, 0.01800671, 0.02225928, 0.02008066,\n",
       "        0.01856422, 0.01779819, 0.0241652 , 0.02945719, 0.02195702,\n",
       "        0.01993017, 0.02708144, 0.02066641, 0.01923871, 0.01768103,\n",
       "        0.02070122, 0.01949511, 0.02177367, 0.02055807, 0.02451663,\n",
       "        0.02068419, 0.02098918, 0.0207787 , 0.02223778, 0.02339015,\n",
       "        0.01867447, 0.0185555 , 0.03444762, 0.02963676, 0.02641931,\n",
       "        0.02530031, 0.02938943, 0.02636814, 0.02204409, 0.02891088,\n",
       "        0.03152299, 0.02320619, 0.02680612, 0.01591754]),\n",
       " 'std_score_time': array([0.01053591, 0.0035781 , 0.0077344 , 0.00646935, 0.0075063 ,\n",
       "        0.00193856, 0.00230214, 0.00152806, 0.00917863, 0.00675179,\n",
       "        0.00354219, 0.0104156 , 0.00609748, 0.00363238, 0.00419418,\n",
       "        0.00762362, 0.00825371, 0.00634726, 0.00384223, 0.00671096,\n",
       "        0.00620033, 0.00709528, 0.00499467, 0.02939145, 0.0041471 ,\n",
       "        0.00315356, 0.00588368, 0.00172218, 0.00180336, 0.00383906,\n",
       "        0.00068279, 0.0018287 , 0.01086077, 0.00268174, 0.00262547,\n",
       "        0.00181484, 0.00317891, 0.00306301, 0.00037233, 0.00162253,\n",
       "        0.00230279, 0.00306224, 0.01206273, 0.00376956, 0.00086491,\n",
       "        0.00278984, 0.0027361 , 0.00134171, 0.00146107, 0.00103828,\n",
       "        0.00075141, 0.0009934 , 0.00367405, 0.01175646, 0.00505066,\n",
       "        0.00461244, 0.0080478 , 0.002625  , 0.00178531, 0.00166618,\n",
       "        0.00119372, 0.00236032, 0.00200644, 0.00470211, 0.00434951,\n",
       "        0.00295747, 0.00288006, 0.00319662, 0.0036606 , 0.00792475,\n",
       "        0.00130596, 0.00146354, 0.01038426, 0.01725951, 0.00307835,\n",
       "        0.00453206, 0.00523194, 0.00460207, 0.00336094, 0.00464172,\n",
       "        0.00546415, 0.00242711, 0.00336672, 0.00214619]),\n",
       " 'param_classifier__activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__alpha': masked_array(data=[1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05, 1e-05,\n",
       "                    1e-05, 1e-05, 1e-05, 1e-05, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__hidden_layer_sizes': masked_array(data=[(150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__learning_rate': masked_array(data=['constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive',\n",
       "                    'constant', 'constant', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'adaptive'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__learning_rate_init': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1, 0.0001, 0.001, 0.01, 0.1,\n",
       "                    0.0001, 0.001, 0.01, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1e-05,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.001,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.01,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.1},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.001},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.01},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 1,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.1}],\n",
       " 'split0_test_balanced_accuracy': array([0.85917191, 0.82105052, 0.52805507, 0.5       , 0.85917191,\n",
       "        0.82105052, 0.52805507, 0.5       , 0.85917191, 0.82105052,\n",
       "        0.52805507, 0.5       , 0.85917191, 0.82218947, 0.53033298,\n",
       "        0.51138952, 0.85917191, 0.82218947, 0.53033298, 0.51138952,\n",
       "        0.85917191, 0.82218947, 0.53033298, 0.51138952, 0.85917191,\n",
       "        0.82840346, 0.51904395, 0.5       , 0.85917191, 0.82840346,\n",
       "        0.51904395, 0.5       , 0.85917191, 0.82840346, 0.51904395,\n",
       "        0.5       , 0.85803296, 0.78998057, 0.52411899, 0.5       ,\n",
       "        0.85803296, 0.78998057, 0.52411899, 0.5       , 0.85803296,\n",
       "        0.78998057, 0.52411899, 0.5       , 0.85181897, 0.81939234,\n",
       "        0.53540801, 0.5       , 0.85181897, 0.81939234, 0.53540801,\n",
       "        0.5       , 0.85181897, 0.81939234, 0.53540801, 0.5       ,\n",
       "        0.8463252 , 0.83399772, 0.5546697 , 0.5       , 0.8463252 ,\n",
       "        0.83399772, 0.5546697 , 0.5       , 0.8463252 , 0.83399772,\n",
       "        0.5546697 , 0.5       , 0.85585555, 0.83793381, 0.53416856,\n",
       "        0.5       , 0.85585555, 0.83793381, 0.53416856, 0.5       ,\n",
       "        0.85585555, 0.83793381, 0.53416856, 0.5       ]),\n",
       " 'split1_test_balanced_accuracy': array([0.80230805, 0.78666421, 0.50433807, 0.5       , 0.80230805,\n",
       "        0.78666421, 0.50433807, 0.5       , 0.80230805, 0.78666421,\n",
       "        0.50433807, 0.5       , 0.80230805, 0.77195833, 0.54617781,\n",
       "        0.5       , 0.80230805, 0.77195833, 0.54617781, 0.5       ,\n",
       "        0.80230805, 0.77195833, 0.54617781, 0.5       , 0.80230805,\n",
       "        0.78666421, 0.53147193, 0.5       , 0.80230805, 0.78666421,\n",
       "        0.53147193, 0.5       , 0.80230805, 0.78666421, 0.53147193,\n",
       "        0.5       , 0.76626357, 0.76968042, 0.50206016, 0.5       ,\n",
       "        0.76626357, 0.76968042, 0.50206016, 0.5       , 0.76626357,\n",
       "        0.76968042, 0.50206016, 0.5       , 0.75891063, 0.78946134,\n",
       "        0.51169101, 0.5       , 0.75891063, 0.78946134, 0.51169101,\n",
       "        0.5       , 0.75891063, 0.78946134, 0.51169101, 0.5       ,\n",
       "        0.80904127, 0.82840346, 0.54897494, 0.50113895, 0.80904127,\n",
       "        0.82840346, 0.54897494, 0.50113895, 0.80904127, 0.82840346,\n",
       "        0.54897494, 0.50113895, 0.81525526, 0.85491759, 0.53882487,\n",
       "        0.5022779 , 0.81525526, 0.85491759, 0.53882487, 0.5022779 ,\n",
       "        0.81525526, 0.85491759, 0.53882487, 0.5022779 ]),\n",
       " 'split2_test_balanced_accuracy': array([0.82374715, 0.80634463, 0.55694761, 0.5       , 0.82374715,\n",
       "        0.80634463, 0.55694761, 0.5       , 0.82374715, 0.80634463,\n",
       "        0.55694761, 0.5       , 0.82374715, 0.80748359, 0.54338068,\n",
       "        0.50455581, 0.82374715, 0.80748359, 0.54338068, 0.50455581,\n",
       "        0.82374715, 0.80748359, 0.54338068, 0.50455581, 0.82374715,\n",
       "        0.7904998 , 0.55756733, 0.5       , 0.82374715, 0.7904998 ,\n",
       "        0.55756733, 0.5       , 0.82374715, 0.7904998 , 0.55756733,\n",
       "        0.5       , 0.82374715, 0.80634463, 0.55301152, 0.5       ,\n",
       "        0.82374715, 0.80634463, 0.55301152, 0.5       , 0.82374715,\n",
       "        0.80634463, 0.55301152, 0.5       , 0.83048037, 0.80520568,\n",
       "        0.55642838, 0.5       , 0.83048037, 0.80520568, 0.55642838,\n",
       "        0.5       , 0.83048037, 0.80520568, 0.55642838, 0.5       ,\n",
       "        0.83389723, 0.8012696 , 0.55580866, 0.53986333, 0.83389723,\n",
       "        0.8012696 , 0.55580866, 0.53986333, 0.83389723, 0.8012696 ,\n",
       "        0.55580866, 0.53986333, 0.81018022, 0.84125017, 0.55580866,\n",
       "        0.5       , 0.81018022, 0.84125017, 0.55580866, 0.5       ,\n",
       "        0.81018022, 0.84125017, 0.55580866, 0.5       ]),\n",
       " 'split3_test_balanced_accuracy': array([0.80728259, 0.79899169, 0.54617781, 0.5       , 0.80728259,\n",
       "        0.79899169, 0.54617781, 0.5       , 0.80728259, 0.79899169,\n",
       "        0.54617781, 0.5       , 0.80728259, 0.80178882, 0.55125285,\n",
       "        0.50599625, 0.80728259, 0.80178882, 0.55125285, 0.50599625,\n",
       "        0.80728259, 0.80178882, 0.55125285, 0.50599625, 0.80614364,\n",
       "        0.80914177, 0.55125285, 0.5       , 0.80614364, 0.80914177,\n",
       "        0.55125285, 0.5       , 0.80614364, 0.80914177, 0.55125285,\n",
       "        0.5       , 0.80500469, 0.80686386, 0.54617781, 0.5       ,\n",
       "        0.80500469, 0.80686386, 0.54617781, 0.5       , 0.80500469,\n",
       "        0.80686386, 0.54617781, 0.5       , 0.79485462, 0.78490553,\n",
       "        0.54783599, 0.5       , 0.79485462, 0.78490553, 0.54783599,\n",
       "        0.5       , 0.79485462, 0.78490553, 0.54783599, 0.5       ,\n",
       "        0.78926035, 0.80262629, 0.53644647, 0.5       , 0.78926035,\n",
       "        0.80262629, 0.53644647, 0.5       , 0.78926035, 0.80262629,\n",
       "        0.53644647, 0.5       , 0.80366475, 0.79475412, 0.53644647,\n",
       "        0.53644647, 0.80366475, 0.79475412, 0.53644647, 0.53644647,\n",
       "        0.80366475, 0.79475412, 0.53644647, 0.53644647]),\n",
       " 'split4_test_balanced_accuracy': array([0.76952368, 0.7332302 , 0.56378132, 0.50113895, 0.76952368,\n",
       "        0.7332302 , 0.56378132, 0.50113895, 0.76952368, 0.7332302 ,\n",
       "        0.56378132, 0.50113895, 0.76952368, 0.73436916, 0.56378132,\n",
       "        0.50113895, 0.76952368, 0.73436916, 0.56378132, 0.50113895,\n",
       "        0.76952368, 0.73436916, 0.56378132, 0.50113895, 0.76382892,\n",
       "        0.73436916, 0.56378132, 0.5       , 0.76382892, 0.73436916,\n",
       "        0.56378132, 0.5       , 0.76382892, 0.73436916, 0.56378132,\n",
       "        0.5       , 0.78963384, 0.72804542, 0.56605923, 0.5       ,\n",
       "        0.78963384, 0.72804542, 0.56605923, 0.5       , 0.78963384,\n",
       "        0.72804542, 0.56605923, 0.5       , 0.7833101 , 0.74815558,\n",
       "        0.55341176, 0.5       , 0.7833101 , 0.74815558, 0.55341176,\n",
       "        0.5       , 0.7833101 , 0.74815558, 0.55341176, 0.5       ,\n",
       "        0.79544759, 0.79203073, 0.56378132, 0.5       , 0.79544759,\n",
       "        0.79203073, 0.56378132, 0.5       , 0.79544759, 0.79203073,\n",
       "        0.56378132, 0.5       , 0.81693469, 0.78912386, 0.56264237,\n",
       "        0.5501139 , 0.81693469, 0.78912386, 0.56264237, 0.5501139 ,\n",
       "        0.81693469, 0.78912386, 0.56264237, 0.5501139 ]),\n",
       " 'mean_test_balanced_accuracy': array([0.81240668, 0.78925625, 0.53985998, 0.50022779, 0.81240668,\n",
       "        0.78925625, 0.53985998, 0.50022779, 0.81240668, 0.78925625,\n",
       "        0.53985998, 0.50022779, 0.81240668, 0.78755787, 0.54698513,\n",
       "        0.50461611, 0.81240668, 0.78755787, 0.54698513, 0.50461611,\n",
       "        0.81240668, 0.78755787, 0.54698513, 0.50461611, 0.81103994,\n",
       "        0.78981568, 0.54462348, 0.5       , 0.81103994, 0.78981568,\n",
       "        0.54462348, 0.5       , 0.81103994, 0.78981568, 0.54462348,\n",
       "        0.5       , 0.80853644, 0.78018298, 0.53828554, 0.5       ,\n",
       "        0.80853644, 0.78018298, 0.53828554, 0.5       , 0.80853644,\n",
       "        0.78018298, 0.53828554, 0.5       , 0.80387494, 0.78942409,\n",
       "        0.54095503, 0.5       , 0.80387494, 0.78942409, 0.54095503,\n",
       "        0.5       , 0.80387494, 0.78942409, 0.54095503, 0.5       ,\n",
       "        0.81479433, 0.81166556, 0.55193622, 0.50820046, 0.81479433,\n",
       "        0.81166556, 0.55193622, 0.50820046, 0.81479433, 0.81166556,\n",
       "        0.55193622, 0.50820046, 0.82037809, 0.82359591, 0.54557819,\n",
       "        0.51776765, 0.82037809, 0.82359591, 0.54557819, 0.51776765,\n",
       "        0.82037809, 0.82359591, 0.54557819, 0.51776765]),\n",
       " 'std_test_balanced_accuracy': array([0.02926699, 0.030144  , 0.02147228, 0.00045558, 0.02926699,\n",
       "        0.030144  , 0.02147228, 0.00045558, 0.02926699, 0.030144  ,\n",
       "        0.02147228, 0.00045558, 0.02926699, 0.0312131 , 0.01087441,\n",
       "        0.00402956, 0.02926699, 0.0312131 , 0.01087441, 0.00402956,\n",
       "        0.02926699, 0.0312131 , 0.01087441, 0.00402956, 0.03100729,\n",
       "        0.03145546, 0.01676777, 0.        , 0.03100729, 0.03145546,\n",
       "        0.01676777, 0.        , 0.03100729, 0.03145546, 0.01676777,\n",
       "        0.        , 0.03110643, 0.02939702, 0.02264283, 0.        ,\n",
       "        0.03110643, 0.02939702, 0.02264283, 0.        , 0.03110643,\n",
       "        0.02939702, 0.02264283, 0.        , 0.03326424, 0.02396107,\n",
       "        0.01630395, 0.        , 0.03326424, 0.02396107, 0.01630395,\n",
       "        0.        , 0.03326424, 0.02396107, 0.01630395, 0.        ,\n",
       "        0.02199316, 0.01645718, 0.00907167, 0.01583758, 0.02199316,\n",
       "        0.01645718, 0.00907167, 0.01583758, 0.02199316, 0.01645718,\n",
       "        0.00907167, 0.01583758, 0.01833076, 0.02652722, 0.01144573,\n",
       "        0.02129079, 0.01833076, 0.02652722, 0.01144573, 0.02129079,\n",
       "        0.01833076, 0.02652722, 0.01144573, 0.02129079]),\n",
       " 'rank_test_balanced_accuracy': array([10, 34, 58, 73, 10, 34, 58, 73, 10, 34, 58, 73, 10, 37, 46, 70, 10,\n",
       "        37, 46, 70, 10, 37, 46, 70, 19, 28, 52, 76, 19, 28, 52, 76, 19, 28,\n",
       "        52, 76, 22, 40, 61, 76, 22, 40, 61, 76, 22, 40, 61, 76, 25, 31, 55,\n",
       "        76, 25, 31, 55, 76, 25, 31, 55, 76,  7, 16, 43, 67,  7, 16, 43, 67,\n",
       "         7, 16, 43, 67,  4,  1, 49, 64,  4,  1, 49, 64,  4,  1, 49, 64],\n",
       "       dtype=int32),\n",
       " 'split0_train_balanced_accuracy': array([0.82702006, 0.85957266, 0.55638969, 0.5       , 0.82702006,\n",
       "        0.85957266, 0.55638969, 0.5       , 0.82702006, 0.85957266,\n",
       "        0.55638969, 0.5       , 0.82702006, 0.85091705, 0.55638969,\n",
       "        0.51338269, 0.82702006, 0.85091705, 0.55638969, 0.51338269,\n",
       "        0.82702006, 0.85091705, 0.55638969, 0.51338269, 0.8273048 ,\n",
       "        0.85900319, 0.55142411, 0.5       , 0.8273048 , 0.85900319,\n",
       "        0.55142411, 0.5       , 0.8273048 , 0.85900319, 0.55142411,\n",
       "        0.5       , 0.82702006, 0.8634224 , 0.55738049, 0.5       ,\n",
       "        0.82702006, 0.8634224 , 0.55738049, 0.5       , 0.82702006,\n",
       "        0.8634224 , 0.55738049, 0.5       , 0.82558482, 0.83217057,\n",
       "        0.55652628, 0.5       , 0.82558482, 0.83217057, 0.55652628,\n",
       "        0.5       , 0.82558482, 0.83217057, 0.55652628, 0.5       ,\n",
       "        0.82353596, 0.81922076, 0.55894077, 0.5       , 0.82353596,\n",
       "        0.81922076, 0.55894077, 0.5       , 0.82353596, 0.81922076,\n",
       "        0.55894077, 0.5       , 0.82335314, 0.82758008, 0.54071754,\n",
       "        0.5       , 0.82335314, 0.82758008, 0.54071754, 0.5       ,\n",
       "        0.82335314, 0.82758008, 0.54071754, 0.5       ]),\n",
       " 'split1_train_balanced_accuracy': array([0.83223781, 0.82735313, 0.54717616, 0.5       , 0.83223781,\n",
       "        0.82735313, 0.54717616, 0.5       , 0.83223781, 0.82735313,\n",
       "        0.54717616, 0.5       , 0.83223781, 0.8236631 , 0.55425993,\n",
       "        0.5       , 0.83223781, 0.8236631 , 0.55425993, 0.5       ,\n",
       "        0.83223781, 0.8236631 , 0.55425993, 0.5       , 0.83223781,\n",
       "        0.82664707, 0.55326913, 0.5       , 0.83223781, 0.82664707,\n",
       "        0.55326913, 0.5       , 0.83223781, 0.82664707, 0.55326913,\n",
       "        0.5       , 0.81329905, 0.81997306, 0.54434033, 0.5       ,\n",
       "        0.81329905, 0.81997306, 0.54434033, 0.5       , 0.81329905,\n",
       "        0.81997306, 0.54434033, 0.5       , 0.81187536, 0.81514407,\n",
       "        0.5460372 , 0.5       , 0.81187536, 0.81514407, 0.5460372 ,\n",
       "        0.5       , 0.81187536, 0.81514407, 0.5460372 , 0.5       ,\n",
       "        0.82609861, 0.82871904, 0.55438497, 0.50056948, 0.82609861,\n",
       "        0.82871904, 0.55438497, 0.50056948, 0.82609861, 0.82871904,\n",
       "        0.55438497, 0.50056948, 0.82595046, 0.82414011, 0.55355387,\n",
       "        0.50056948, 0.82595046, 0.82414011, 0.55355387, 0.50056948,\n",
       "        0.82595046, 0.82414011, 0.55355387, 0.50056948]),\n",
       " 'split2_train_balanced_accuracy': array([0.83607599, 0.8470673 , 0.55296128, 0.5       , 0.83607599,\n",
       "        0.8470673 , 0.55296128, 0.5       , 0.83607599, 0.8470673 ,\n",
       "        0.55296128, 0.5       , 0.83607599, 0.84224987, 0.54940783,\n",
       "        0.50455581, 0.83607599, 0.84224987, 0.54940783, 0.50455581,\n",
       "        0.83607599, 0.84224987, 0.54940783, 0.50455581, 0.83607599,\n",
       "        0.84026826, 0.55396364, 0.5       , 0.83607599, 0.84026826,\n",
       "        0.55396364, 0.5       , 0.83607599, 0.84026826, 0.55396364,\n",
       "        0.5       , 0.83607599, 0.84678257, 0.54856517, 0.5       ,\n",
       "        0.83607599, 0.84678257, 0.54856517, 0.5       , 0.83607599,\n",
       "        0.84678257, 0.54856517, 0.5       , 0.84016424, 0.81742198,\n",
       "        0.55353075, 0.5       , 0.84016424, 0.81742198, 0.55353075,\n",
       "        0.5       , 0.84016424, 0.81742198, 0.55353075, 0.5       ,\n",
       "        0.82713564, 0.80351604, 0.54783599, 0.53559226, 0.82713564,\n",
       "        0.80351604, 0.54783599, 0.53559226, 0.82713564, 0.80351604,\n",
       "        0.54783599, 0.53559226, 0.81309312, 0.8288094 , 0.54584282,\n",
       "        0.5       , 0.81309312, 0.8288094 , 0.54584282, 0.5       ,\n",
       "        0.81309312, 0.8288094 , 0.54584282, 0.5       ]),\n",
       " 'split3_train_balanced_accuracy': array([0.83833078, 0.84735204, 0.54476166, 0.5       , 0.83833078,\n",
       "        0.84735204, 0.54476166, 0.5       , 0.83833078, 0.84735204,\n",
       "        0.54476166, 0.5       , 0.83833078, 0.86238537, 0.55085463,\n",
       "        0.49577726, 0.83833078, 0.86238537, 0.55085463, 0.49577726,\n",
       "        0.83833078, 0.86238537, 0.55085463, 0.49577726, 0.83833078,\n",
       "        0.85626928, 0.55682258, 0.50085421, 0.83833078, 0.85626928,\n",
       "        0.55682258, 0.50085421, 0.83833078, 0.85626928, 0.55682258,\n",
       "        0.50085421, 0.83804605, 0.8591051 , 0.5494425 , 0.5022779 ,\n",
       "        0.83804605, 0.8591051 , 0.5494425 , 0.5022779 , 0.83804605,\n",
       "        0.8591051 , 0.5494425 , 0.5022779 , 0.83536993, 0.84070115,\n",
       "        0.55168573, 0.5       , 0.83536993, 0.84070115, 0.55168573,\n",
       "        0.5       , 0.83536993, 0.84070115, 0.55168573, 0.5       ,\n",
       "        0.82346872, 0.8350274 , 0.54527335, 0.5       , 0.82346872,\n",
       "        0.8350274 , 0.54527335, 0.5       , 0.82346872, 0.8350274 ,\n",
       "        0.54527335, 0.5       , 0.83371719, 0.85192886, 0.54527335,\n",
       "        0.54498861, 0.83371719, 0.85192886, 0.54527335, 0.54498861,\n",
       "        0.83371719, 0.85192886, 0.54527335, 0.54498861]),\n",
       " 'split4_train_balanced_accuracy': array([0.81763366, 0.84507319, 0.54731676, 0.5022779 , 0.81763366,\n",
       "        0.84507319, 0.54731676, 0.5022779 , 0.81763366, 0.84507319,\n",
       "        0.54731676, 0.5022779 , 0.81763366, 0.84478846, 0.54703202,\n",
       "        0.50199317, 0.81763366, 0.84478846, 0.54703202, 0.50199317,\n",
       "        0.81763366, 0.84478846, 0.54703202, 0.50199317, 0.82907762,\n",
       "        0.84450372, 0.54801605, 0.5       , 0.82907762, 0.84450372,\n",
       "        0.54801605, 0.5       , 0.82907762, 0.84450372, 0.54801605,\n",
       "        0.5       , 0.8211552 , 0.8350278 , 0.54943974, 0.5       ,\n",
       "        0.8211552 , 0.8350278 , 0.54943974, 0.5       , 0.8211552 ,\n",
       "        0.8350278 , 0.54943974, 0.5       , 0.81820314, 0.80574585,\n",
       "        0.53970421, 0.50028474, 0.81820314, 0.80574585, 0.53970421,\n",
       "        0.50028474, 0.81820314, 0.80574585, 0.53970421, 0.50028474,\n",
       "        0.81572005, 0.83311838, 0.55125285, 0.50113895, 0.81572005,\n",
       "        0.83311838, 0.55125285, 0.50113895, 0.81572005, 0.83311838,\n",
       "        0.55125285, 0.50113895, 0.82051454, 0.83272896, 0.55125285,\n",
       "        0.54328018, 0.82051454, 0.83272896, 0.55125285, 0.54328018,\n",
       "        0.82051454, 0.83272896, 0.55125285, 0.54328018]),\n",
       " 'mean_train_balanced_accuracy': array([0.83025966, 0.84528367, 0.54972111, 0.50045558, 0.83025966,\n",
       "        0.84528367, 0.54972111, 0.50045558, 0.83025966, 0.84528367,\n",
       "        0.54972111, 0.50045558, 0.83025966, 0.84480077, 0.55158882,\n",
       "        0.50314178, 0.83025966, 0.84480077, 0.55158882, 0.50314178,\n",
       "        0.83025966, 0.84480077, 0.55158882, 0.50314178, 0.8326054 ,\n",
       "        0.8453383 , 0.5526991 , 0.50017084, 0.8326054 , 0.8453383 ,\n",
       "        0.5526991 , 0.50017084, 0.8326054 , 0.8453383 , 0.5526991 ,\n",
       "        0.50017084, 0.82711927, 0.84486219, 0.54983365, 0.50045558,\n",
       "        0.82711927, 0.84486219, 0.54983365, 0.50045558, 0.82711927,\n",
       "        0.84486219, 0.54983365, 0.50045558, 0.8262395 , 0.82223672,\n",
       "        0.54949684, 0.50005695, 0.8262395 , 0.82223672, 0.54949684,\n",
       "        0.50005695, 0.8262395 , 0.82223672, 0.54949684, 0.50005695,\n",
       "        0.8231918 , 0.82392033, 0.55153759, 0.50746014, 0.8231918 ,\n",
       "        0.82392033, 0.55153759, 0.50746014, 0.8231918 , 0.82392033,\n",
       "        0.55153759, 0.50746014, 0.82332569, 0.83303748, 0.54732809,\n",
       "        0.51776765, 0.82332569, 0.83303748, 0.54732809, 0.51776765,\n",
       "        0.82332569, 0.83303748, 0.54732809, 0.51776765]),\n",
       " 'std_train_balanced_accuracy': array([0.00738643, 0.0103265 , 0.00428538, 0.00091116, 0.00738643,\n",
       "        0.0103265 , 0.00428538, 0.00091116, 0.00738643, 0.0103265 ,\n",
       "        0.00428538, 0.00091116, 0.00738643, 0.0126486 , 0.0033539 ,\n",
       "        0.0058703 , 0.00738643, 0.0126486 , 0.0033539 , 0.0058703 ,\n",
       "        0.00738643, 0.0126486 , 0.0033539 , 0.0058703 , 0.00413526,\n",
       "        0.01167886, 0.00291491, 0.00034169, 0.00413526, 0.01167886,\n",
       "        0.00291491, 0.00034169, 0.00413526, 0.01167886, 0.00291491,\n",
       "        0.00034169, 0.0092325 , 0.01591989, 0.00422016, 0.00091116,\n",
       "        0.0092325 , 0.01591989, 0.00422016, 0.00091116, 0.0092325 ,\n",
       "        0.01591989, 0.00422016, 0.00091116, 0.01047476, 0.01253039,\n",
       "        0.00597229, 0.0001139 , 0.01047476, 0.01253039, 0.00597229,\n",
       "        0.0001139 , 0.01047476, 0.01253039, 0.00597229, 0.0001139 ,\n",
       "        0.00400064, 0.01157082, 0.00481536, 0.0140724 , 0.00400064,\n",
       "        0.01157082, 0.00481536, 0.0140724 , 0.00400064, 0.01157082,\n",
       "        0.00481536, 0.0140724 , 0.00674509, 0.00983669, 0.00456709,\n",
       "        0.02153614, 0.00674509, 0.00983669, 0.00456709, 0.02153614,\n",
       "        0.00674509, 0.00983669, 0.00456709, 0.02153614]),\n",
       " 'split0_test_sensitivity': array([0.88235294, 0.70588235, 0.95588235, 0.        , 0.88235294,\n",
       "        0.70588235, 0.95588235, 0.        , 0.88235294, 0.70588235,\n",
       "        0.95588235, 0.        , 0.88235294, 0.70588235, 0.95588235,\n",
       "        1.        , 0.88235294, 0.70588235, 0.95588235, 1.        ,\n",
       "        0.88235294, 0.70588235, 0.95588235, 1.        , 0.88235294,\n",
       "        0.72058824, 0.92647059, 0.        , 0.88235294, 0.72058824,\n",
       "        0.92647059, 0.        , 0.88235294, 0.72058824, 0.92647059,\n",
       "        0.        , 0.88235294, 0.63235294, 0.94117647, 0.        ,\n",
       "        0.88235294, 0.63235294, 0.94117647, 0.        , 0.88235294,\n",
       "        0.63235294, 0.94117647, 0.        , 0.86764706, 0.69117647,\n",
       "        0.97058824, 1.        , 0.86764706, 0.69117647, 0.97058824,\n",
       "        1.        , 0.86764706, 0.69117647, 0.97058824, 1.        ,\n",
       "        0.80882353, 0.75      , 1.        , 0.        , 0.80882353,\n",
       "        0.75      , 1.        , 0.        , 0.80882353, 0.75      ,\n",
       "        1.        , 0.        , 0.85294118, 0.76470588, 1.        ,\n",
       "        0.        , 0.85294118, 0.76470588, 1.        , 0.        ,\n",
       "        0.85294118, 0.76470588, 1.        , 0.        ]),\n",
       " 'split1_test_sensitivity': array([0.69117647, 0.60294118, 0.89705882, 1.        , 0.69117647,\n",
       "        0.60294118, 0.89705882, 1.        , 0.69117647, 0.60294118,\n",
       "        0.89705882, 1.        , 0.69117647, 0.57352941, 0.98529412,\n",
       "        1.        , 0.69117647, 0.57352941, 0.98529412, 1.        ,\n",
       "        0.69117647, 0.57352941, 0.98529412, 1.        , 0.69117647,\n",
       "        0.60294118, 0.95588235, 1.        , 0.69117647, 0.60294118,\n",
       "        0.95588235, 1.        , 0.69117647, 0.60294118, 0.95588235,\n",
       "        1.        , 0.57352941, 0.57352941, 0.89705882, 1.        ,\n",
       "        0.57352941, 0.57352941, 0.89705882, 1.        , 0.57352941,\n",
       "        0.57352941, 0.89705882, 1.        , 0.55882353, 0.61764706,\n",
       "        0.91176471, 0.        , 0.55882353, 0.61764706, 0.91176471,\n",
       "        0.        , 0.55882353, 0.61764706, 0.91176471, 0.        ,\n",
       "        0.72058824, 0.72058824, 1.        , 1.        , 0.72058824,\n",
       "        0.72058824, 1.        , 1.        , 0.72058824, 0.72058824,\n",
       "        1.        , 1.        , 0.73529412, 0.79411765, 0.97058824,\n",
       "        1.        , 0.73529412, 0.79411765, 0.97058824, 1.        ,\n",
       "        0.73529412, 0.79411765, 0.97058824, 1.        ]),\n",
       " 'split2_test_sensitivity': array([0.75      , 0.67647059, 1.        , 1.        , 0.75      ,\n",
       "        0.67647059, 1.        , 1.        , 0.75      , 0.67647059,\n",
       "        1.        , 1.        , 0.75      , 0.67647059, 0.97058824,\n",
       "        1.        , 0.75      , 0.67647059, 0.97058824, 1.        ,\n",
       "        0.75      , 0.67647059, 0.97058824, 1.        , 0.75      ,\n",
       "        0.64705882, 0.98529412, 1.        , 0.75      , 0.64705882,\n",
       "        0.98529412, 1.        , 0.75      , 0.64705882, 0.98529412,\n",
       "        1.        , 0.75      , 0.67647059, 0.98529412, 1.        ,\n",
       "        0.75      , 0.67647059, 0.98529412, 1.        , 0.75      ,\n",
       "        0.67647059, 0.98529412, 1.        , 0.77941176, 0.67647059,\n",
       "        0.98529412, 0.        , 0.77941176, 0.67647059, 0.98529412,\n",
       "        0.        , 0.77941176, 0.67647059, 0.98529412, 0.        ,\n",
       "        0.77941176, 0.66176471, 1.        , 1.        , 0.77941176,\n",
       "        0.66176471, 1.        , 1.        , 0.77941176, 0.66176471,\n",
       "        1.        , 1.        , 0.72058824, 0.79411765, 1.        ,\n",
       "        0.        , 0.72058824, 0.79411765, 1.        , 0.        ,\n",
       "        0.72058824, 0.79411765, 1.        , 0.        ]),\n",
       " 'split3_test_sensitivity': array([0.73529412, 0.66176471, 0.98529412, 1.        , 0.73529412,\n",
       "        0.66176471, 0.98529412, 1.        , 0.73529412, 0.66176471,\n",
       "        0.98529412, 1.        , 0.73529412, 0.67647059, 1.        ,\n",
       "        0.91176471, 0.73529412, 0.67647059, 1.        , 0.91176471,\n",
       "        0.73529412, 0.67647059, 1.        , 0.91176471, 0.73529412,\n",
       "        0.69117647, 1.        , 1.        , 0.73529412, 0.69117647,\n",
       "        1.        , 1.        , 0.73529412, 0.69117647, 1.        ,\n",
       "        1.        , 0.73529412, 0.69117647, 0.98529412, 1.        ,\n",
       "        0.73529412, 0.69117647, 0.98529412, 1.        , 0.73529412,\n",
       "        0.69117647, 0.98529412, 1.        , 0.70588235, 0.61764706,\n",
       "        1.        , 0.        , 0.70588235, 0.61764706, 1.        ,\n",
       "        0.        , 0.70588235, 0.61764706, 1.        , 0.        ,\n",
       "        0.67647059, 0.76470588, 1.        , 0.        , 0.67647059,\n",
       "        0.76470588, 1.        , 0.        , 0.67647059, 0.76470588,\n",
       "        1.        , 0.        , 0.79411765, 0.73529412, 1.        ,\n",
       "        1.        , 0.79411765, 0.73529412, 1.        , 1.        ,\n",
       "        0.79411765, 0.73529412, 1.        , 1.        ]),\n",
       " 'split4_test_sensitivity': array([0.6119403 , 0.50746269, 1.        , 1.        , 0.6119403 ,\n",
       "        0.50746269, 1.        , 1.        , 0.6119403 , 0.50746269,\n",
       "        1.        , 1.        , 0.6119403 , 0.50746269, 1.        ,\n",
       "        1.        , 0.6119403 , 0.50746269, 1.        , 1.        ,\n",
       "        0.6119403 , 0.50746269, 1.        , 1.        , 0.6119403 ,\n",
       "        0.50746269, 1.        , 1.        , 0.6119403 , 0.50746269,\n",
       "        1.        , 1.        , 0.6119403 , 0.50746269, 1.        ,\n",
       "        1.        , 0.65671642, 0.49253731, 1.        , 1.        ,\n",
       "        0.65671642, 0.49253731, 1.        , 1.        , 0.65671642,\n",
       "        0.49253731, 1.        , 1.        , 0.64179104, 0.53731343,\n",
       "        0.97014925, 1.        , 0.64179104, 0.53731343, 0.97014925,\n",
       "        1.        , 0.64179104, 0.53731343, 0.97014925, 1.        ,\n",
       "        0.68656716, 0.68656716, 1.        , 1.        , 0.68656716,\n",
       "        0.68656716, 1.        , 1.        , 0.68656716, 0.68656716,\n",
       "        1.        , 1.        , 0.79104478, 0.67164179, 1.        ,\n",
       "        1.        , 0.79104478, 0.67164179, 1.        , 1.        ,\n",
       "        0.79104478, 0.67164179, 1.        , 1.        ]),\n",
       " 'mean_test_sensitivity': array([0.73415277, 0.6309043 , 0.96764706, 0.8       , 0.73415277,\n",
       "        0.6309043 , 0.96764706, 0.8       , 0.73415277, 0.6309043 ,\n",
       "        0.96764706, 0.8       , 0.73415277, 0.62796313, 0.98235294,\n",
       "        0.98235294, 0.73415277, 0.62796313, 0.98235294, 0.98235294,\n",
       "        0.73415277, 0.62796313, 0.98235294, 0.98235294, 0.73415277,\n",
       "        0.63384548, 0.97352941, 0.8       , 0.73415277, 0.63384548,\n",
       "        0.97352941, 0.8       , 0.73415277, 0.63384548, 0.97352941,\n",
       "        0.8       , 0.71957858, 0.61321335, 0.96176471, 0.8       ,\n",
       "        0.71957858, 0.61321335, 0.96176471, 0.8       , 0.71957858,\n",
       "        0.61321335, 0.96176471, 0.8       , 0.71071115, 0.62805092,\n",
       "        0.96755926, 0.4       , 0.71071115, 0.62805092, 0.96755926,\n",
       "        0.4       , 0.71071115, 0.62805092, 0.96755926, 0.4       ,\n",
       "        0.73437226, 0.7167252 , 1.        , 0.6       , 0.73437226,\n",
       "        0.7167252 , 1.        , 0.6       , 0.73437226, 0.7167252 ,\n",
       "        1.        , 0.6       , 0.77879719, 0.75197542, 0.99411765,\n",
       "        0.6       , 0.77879719, 0.75197542, 0.99411765, 0.6       ,\n",
       "        0.77879719, 0.75197542, 0.99411765, 0.6       ]),\n",
       " 'std_test_sensitivity': array([0.088316  , 0.07024262, 0.03879678, 0.4       , 0.088316  ,\n",
       "        0.07024262, 0.03879678, 0.4       , 0.088316  , 0.07024262,\n",
       "        0.03879678, 0.4       , 0.088316  , 0.07518077, 0.01714986,\n",
       "        0.03529412, 0.088316  , 0.07518077, 0.01714986, 0.03529412,\n",
       "        0.088316  , 0.07518077, 0.01714986, 0.03529412, 0.088316  ,\n",
       "        0.07471737, 0.02851576, 0.4       , 0.088316  , 0.07471737,\n",
       "        0.02851576, 0.4       , 0.088316  , 0.07471737, 0.02851576,\n",
       "        0.4       , 0.10290767, 0.0729158 , 0.03789441, 0.4       ,\n",
       "        0.10290767, 0.0729158 , 0.03789441, 0.4       , 0.10290767,\n",
       "        0.0729158 , 0.03789441, 0.4       , 0.10695027, 0.0543674 ,\n",
       "        0.02998614, 0.48989795, 0.10695027, 0.0543674 , 0.02998614,\n",
       "        0.48989795, 0.10695027, 0.0543674 , 0.02998614, 0.48989795,\n",
       "        0.05176771, 0.03835217, 0.        , 0.48989795, 0.05176771,\n",
       "        0.03835217, 0.        , 0.48989795, 0.05176771, 0.03835217,\n",
       "        0.        , 0.48989795, 0.04725008, 0.04570724, 0.01176471,\n",
       "        0.48989795, 0.04725008, 0.04570724, 0.01176471, 0.48989795,\n",
       "        0.04725008, 0.04570724, 0.01176471, 0.48989795]),\n",
       " 'rank_test_sensitivity': array([43, 64, 16, 25, 43, 64, 16, 25, 43, 64, 16, 25, 43, 70,  7,  7, 43,\n",
       "        70,  7,  7, 43, 70,  7,  7, 43, 61, 13, 25, 43, 61, 13, 25, 43, 61,\n",
       "        13, 25, 52, 73, 22, 25, 52, 73, 22, 25, 52, 73, 22, 25, 58, 67, 19,\n",
       "        82, 58, 67, 19, 82, 58, 67, 19, 82, 40, 55,  1, 76, 40, 55,  1, 76,\n",
       "        40, 55,  1, 76, 34, 37,  4, 76, 34, 37,  4, 76, 34, 37,  4, 76],\n",
       "       dtype=int32),\n",
       " 'split0_train_sensitivity': array([0.81918819, 0.7601476 , 0.99261993, 0.        , 0.81918819,\n",
       "        0.7601476 , 0.99261993, 0.        , 0.81918819, 0.7601476 ,\n",
       "        0.99261993, 0.        , 0.81918819, 0.74169742, 0.99261993,\n",
       "        1.        , 0.81918819, 0.74169742, 0.99261993, 1.        ,\n",
       "        0.81918819, 0.74169742, 0.99261993, 1.        , 0.81918819,\n",
       "        0.7601476 , 0.98154982, 0.        , 0.81918819, 0.7601476 ,\n",
       "        0.98154982, 0.        , 0.81918819, 0.7601476 , 0.98154982,\n",
       "        0.        , 0.81918819, 0.75645756, 0.99630996, 0.        ,\n",
       "        0.81918819, 0.75645756, 0.99630996, 0.        , 0.81918819,\n",
       "        0.75645756, 0.99630996, 0.        , 0.82656827, 0.71217712,\n",
       "        0.99630996, 1.        , 0.82656827, 0.71217712, 0.99630996,\n",
       "        1.        , 0.82656827, 0.71217712, 0.99630996, 1.        ,\n",
       "        0.77121771, 0.70848708, 1.        , 0.        , 0.77121771,\n",
       "        0.70848708, 1.        , 0.        , 0.77121771, 0.70848708,\n",
       "        1.        , 0.        , 0.79704797, 0.73431734, 1.        ,\n",
       "        0.        , 0.79704797, 0.73431734, 1.        , 0.        ,\n",
       "        0.79704797, 0.73431734, 1.        , 0.        ]),\n",
       " 'split1_train_sensitivity': array([0.7601476 , 0.69741697, 0.96678967, 1.        , 0.7601476 ,\n",
       "        0.69741697, 0.96678967, 1.        , 0.7601476 , 0.69741697,\n",
       "        0.96678967, 1.        , 0.7601476 , 0.6900369 , 0.98892989,\n",
       "        1.        , 0.7601476 , 0.6900369 , 0.98892989, 1.        ,\n",
       "        0.7601476 , 0.6900369 , 0.98892989, 1.        , 0.7601476 ,\n",
       "        0.69372694, 0.98523985, 1.        , 0.7601476 , 0.69372694,\n",
       "        0.98523985, 1.        , 0.7601476 , 0.69372694, 0.98523985,\n",
       "        1.        , 0.67158672, 0.68265683, 0.95940959, 1.        ,\n",
       "        0.67158672, 0.68265683, 0.95940959, 1.        , 0.67158672,\n",
       "        0.68265683, 0.95940959, 1.        , 0.67158672, 0.67527675,\n",
       "        0.96678967, 0.        , 0.67158672, 0.67527675, 0.96678967,\n",
       "        0.        , 0.67158672, 0.67527675, 0.96678967, 0.        ,\n",
       "        0.77121771, 0.73431734, 1.        , 1.        , 0.77121771,\n",
       "        0.73431734, 1.        , 1.        , 0.77121771, 0.73431734,\n",
       "        1.        , 1.        , 0.77490775, 0.74907749, 0.98523985,\n",
       "        1.        , 0.77490775, 0.74907749, 0.98523985, 1.        ,\n",
       "        0.77490775, 0.74907749, 0.98523985, 1.        ]),\n",
       " 'split2_train_sensitivity': array([0.76383764, 0.74538745, 1.        , 1.        , 0.76383764,\n",
       "        0.74538745, 1.        , 1.        , 0.76383764, 0.74538745,\n",
       "        1.        , 1.        , 0.76383764, 0.73062731, 0.99630996,\n",
       "        1.        , 0.76383764, 0.73062731, 0.99630996, 1.        ,\n",
       "        0.76383764, 0.73062731, 0.99630996, 1.        , 0.76383764,\n",
       "        0.72324723, 0.99630996, 1.        , 0.76383764, 0.72324723,\n",
       "        0.99630996, 1.        , 0.76383764, 0.72324723, 0.99630996,\n",
       "        1.        , 0.76383764, 0.74538745, 0.98892989, 1.        ,\n",
       "        0.76383764, 0.74538745, 0.98892989, 1.        , 0.76383764,\n",
       "        0.74538745, 0.98892989, 1.        , 0.7896679 , 0.67527675,\n",
       "        1.        , 0.        , 0.7896679 , 0.67527675, 1.        ,\n",
       "        0.        , 0.7896679 , 0.67527675, 1.        , 0.        ,\n",
       "        0.74538745, 0.64575646, 1.        , 1.        , 0.74538745,\n",
       "        0.64575646, 1.        , 1.        , 0.74538745, 0.64575646,\n",
       "        1.        , 1.        , 0.71217712, 0.76752768, 1.        ,\n",
       "        0.        , 0.71217712, 0.76752768, 1.        , 0.        ,\n",
       "        0.71217712, 0.76752768, 1.        , 0.        ]),\n",
       " 'split3_train_sensitivity': array([0.77859779, 0.74538745, 0.96309963, 1.        , 0.77859779,\n",
       "        0.74538745, 0.96309963, 1.        , 0.77859779, 0.74538745,\n",
       "        0.96309963, 1.        , 0.77859779, 0.78228782, 0.98154982,\n",
       "        0.87822878, 0.77859779, 0.78228782, 0.98154982, 0.87822878,\n",
       "        0.77859779, 0.78228782, 0.98154982, 0.87822878, 0.77859779,\n",
       "        0.77859779, 0.98892989, 1.        , 0.77859779, 0.77859779,\n",
       "        0.98892989, 1.        , 0.77859779, 0.77859779, 0.98892989,\n",
       "        1.        , 0.77859779, 0.78597786, 0.97416974, 1.        ,\n",
       "        0.77859779, 0.78597786, 0.97416974, 1.        , 0.77859779,\n",
       "        0.78597786, 0.97416974, 1.        , 0.7601476 , 0.7195572 ,\n",
       "        0.99630996, 0.        , 0.7601476 , 0.7195572 , 0.99630996,\n",
       "        0.        , 0.7601476 , 0.7195572 , 0.99630996, 0.        ,\n",
       "        0.72324723, 0.79704797, 1.        , 0.        , 0.72324723,\n",
       "        0.79704797, 1.        , 0.        , 0.72324723, 0.79704797,\n",
       "        1.        , 0.        , 0.81549815, 0.82287823, 1.        ,\n",
       "        1.        , 0.81549815, 0.82287823, 1.        , 1.        ,\n",
       "        0.81549815, 0.82287823, 1.        , 1.        ]),\n",
       " 'split4_train_sensitivity': array([0.70588235, 0.71691176, 0.98529412, 1.        , 0.70588235,\n",
       "        0.71691176, 0.98529412, 1.        , 0.70588235, 0.71691176,\n",
       "        0.98529412, 1.        , 0.70588235, 0.71691176, 0.98529412,\n",
       "        1.        , 0.70588235, 0.71691176, 0.98529412, 1.        ,\n",
       "        0.70588235, 0.71691176, 0.98529412, 1.        , 0.73161765,\n",
       "        0.71691176, 0.98897059, 1.        , 0.73161765, 0.71691176,\n",
       "        0.98897059, 1.        , 0.73161765, 0.71691176, 0.98897059,\n",
       "        1.        , 0.71691176, 0.69852941, 0.98897059, 1.        ,\n",
       "        0.71691176, 0.69852941, 0.98897059, 1.        , 0.71691176,\n",
       "        0.69852941, 0.98897059, 1.        , 0.70588235, 0.64338235,\n",
       "        0.96323529, 1.        , 0.70588235, 0.64338235, 0.96323529,\n",
       "        1.        , 0.70588235, 0.64338235, 0.96323529, 1.        ,\n",
       "        0.72426471, 0.75735294, 1.        , 1.        , 0.72426471,\n",
       "        0.75735294, 1.        , 1.        , 0.72426471, 0.75735294,\n",
       "        1.        , 1.        , 0.77941176, 0.74632353, 1.        ,\n",
       "        1.        , 0.77941176, 0.74632353, 1.        , 1.        ,\n",
       "        0.77941176, 0.74632353, 1.        , 1.        ]),\n",
       " 'mean_train_sensitivity': array([0.76553071, 0.73305025, 0.98156067, 0.8       , 0.76553071,\n",
       "        0.73305025, 0.98156067, 0.8       , 0.76553071, 0.73305025,\n",
       "        0.98156067, 0.8       , 0.76553071, 0.73231224, 0.98894074,\n",
       "        0.97564576, 0.76553071, 0.73231224, 0.98894074, 0.97564576,\n",
       "        0.76553071, 0.73231224, 0.98894074, 0.97564576, 0.77067777,\n",
       "        0.73452626, 0.98820002, 0.8       , 0.77067777, 0.73452626,\n",
       "        0.98820002, 0.8       , 0.77067777, 0.73452626, 0.98820002,\n",
       "        0.8       , 0.75002442, 0.73380182, 0.98155796, 0.8       ,\n",
       "        0.75002442, 0.73380182, 0.98155796, 0.8       , 0.75002442,\n",
       "        0.73380182, 0.98155796, 0.8       , 0.75077057, 0.68513404,\n",
       "        0.98452898, 0.4       , 0.75077057, 0.68513404, 0.98452898,\n",
       "        0.4       , 0.75077057, 0.68513404, 0.98452898, 0.4       ,\n",
       "        0.74706696, 0.72859236, 1.        , 0.6       , 0.74706696,\n",
       "        0.72859236, 1.        , 0.6       , 0.74706696, 0.72859236,\n",
       "        1.        , 0.6       , 0.77580855, 0.76402485, 0.99704797,\n",
       "        0.6       , 0.77580855, 0.76402485, 0.99704797, 0.6       ,\n",
       "        0.77580855, 0.76402485, 0.99704797, 0.6       ]),\n",
       " 'std_train_sensitivity': array([0.03644076, 0.02266654, 0.01438921, 0.4       , 0.03644076,\n",
       "        0.02266654, 0.01438921, 0.4       , 0.03644076, 0.02266654,\n",
       "        0.01438921, 0.4       , 0.03644076, 0.03037387, 0.00521087,\n",
       "        0.04870849, 0.03644076, 0.03037387, 0.00521087, 0.04870849,\n",
       "        0.03644076, 0.03037387, 0.00521087, 0.04870849, 0.02863338,\n",
       "        0.03066211, 0.00489664, 0.4       , 0.02863338, 0.03066211,\n",
       "        0.00489664, 0.4       , 0.02863338, 0.03066211, 0.00489664,\n",
       "        0.4       , 0.05106817, 0.03802579, 0.01320644, 0.4       ,\n",
       "        0.05106817, 0.03802579, 0.01320644, 0.4       , 0.05106817,\n",
       "        0.03802579, 0.01320644, 0.4       , 0.05591289, 0.02776263,\n",
       "        0.01603147, 0.48989795, 0.05591289, 0.02776263, 0.01603147,\n",
       "        0.48989795, 0.05591289, 0.02776263, 0.01603147, 0.48989795,\n",
       "        0.02124458, 0.0506204 , 0.        , 0.48989795, 0.02124458,\n",
       "        0.0506204 , 0.        , 0.48989795, 0.02124458, 0.0506204 ,\n",
       "        0.        , 0.48989795, 0.03489737, 0.03128989, 0.00590406,\n",
       "        0.48989795, 0.03489737, 0.03128989, 0.00590406, 0.48989795,\n",
       "        0.03489737, 0.03128989, 0.00590406, 0.48989795]),\n",
       " 'split0_test_specificity': array([0.83599089, 0.93621868, 0.10022779, 1.        , 0.83599089,\n",
       "        0.93621868, 0.10022779, 1.        , 0.83599089, 0.93621868,\n",
       "        0.10022779, 1.        , 0.83599089, 0.93849658, 0.1047836 ,\n",
       "        0.02277904, 0.83599089, 0.93849658, 0.1047836 , 0.02277904,\n",
       "        0.83599089, 0.93849658, 0.1047836 , 0.02277904, 0.83599089,\n",
       "        0.93621868, 0.11161731, 1.        , 0.83599089, 0.93621868,\n",
       "        0.11161731, 1.        , 0.83599089, 0.93621868, 0.11161731,\n",
       "        1.        , 0.83371298, 0.9476082 , 0.1070615 , 1.        ,\n",
       "        0.83371298, 0.9476082 , 0.1070615 , 1.        , 0.83371298,\n",
       "        0.9476082 , 0.1070615 , 1.        , 0.83599089, 0.9476082 ,\n",
       "        0.10022779, 0.        , 0.83599089, 0.9476082 , 0.10022779,\n",
       "        0.        , 0.83599089, 0.9476082 , 0.10022779, 0.        ,\n",
       "        0.88382688, 0.91799544, 0.10933941, 1.        , 0.88382688,\n",
       "        0.91799544, 0.10933941, 1.        , 0.88382688, 0.91799544,\n",
       "        0.10933941, 1.        , 0.85876993, 0.91116173, 0.06833713,\n",
       "        1.        , 0.85876993, 0.91116173, 0.06833713, 1.        ,\n",
       "        0.85876993, 0.91116173, 0.06833713, 1.        ]),\n",
       " 'split1_test_specificity': array([0.91343964, 0.97038724, 0.11161731, 0.        , 0.91343964,\n",
       "        0.97038724, 0.11161731, 0.        , 0.91343964, 0.97038724,\n",
       "        0.11161731, 0.        , 0.91343964, 0.97038724, 0.1070615 ,\n",
       "        0.        , 0.91343964, 0.97038724, 0.1070615 , 0.        ,\n",
       "        0.91343964, 0.97038724, 0.1070615 , 0.        , 0.91343964,\n",
       "        0.97038724, 0.1070615 , 0.        , 0.91343964, 0.97038724,\n",
       "        0.1070615 , 0.        , 0.91343964, 0.97038724, 0.1070615 ,\n",
       "        0.        , 0.95899772, 0.96583144, 0.1070615 , 0.        ,\n",
       "        0.95899772, 0.96583144, 0.1070615 , 0.        , 0.95899772,\n",
       "        0.96583144, 0.1070615 , 0.        , 0.95899772, 0.96127563,\n",
       "        0.11161731, 1.        , 0.95899772, 0.96127563, 0.11161731,\n",
       "        1.        , 0.95899772, 0.96127563, 0.11161731, 1.        ,\n",
       "        0.89749431, 0.93621868, 0.09794989, 0.0022779 , 0.89749431,\n",
       "        0.93621868, 0.09794989, 0.0022779 , 0.89749431, 0.93621868,\n",
       "        0.09794989, 0.0022779 , 0.8952164 , 0.91571754, 0.1070615 ,\n",
       "        0.00455581, 0.8952164 , 0.91571754, 0.1070615 , 0.00455581,\n",
       "        0.8952164 , 0.91571754, 0.1070615 , 0.00455581]),\n",
       " 'split2_test_specificity': array([0.89749431, 0.93621868, 0.11389522, 0.        , 0.89749431,\n",
       "        0.93621868, 0.11389522, 0.        , 0.89749431, 0.93621868,\n",
       "        0.11389522, 0.        , 0.89749431, 0.93849658, 0.11617312,\n",
       "        0.00911162, 0.89749431, 0.93849658, 0.11617312, 0.00911162,\n",
       "        0.89749431, 0.93849658, 0.11617312, 0.00911162, 0.89749431,\n",
       "        0.93394077, 0.12984055, 0.        , 0.89749431, 0.93394077,\n",
       "        0.12984055, 0.        , 0.89749431, 0.93394077, 0.12984055,\n",
       "        0.        , 0.89749431, 0.93621868, 0.12072893, 0.        ,\n",
       "        0.89749431, 0.93621868, 0.12072893, 0.        , 0.89749431,\n",
       "        0.93621868, 0.12072893, 0.        , 0.88154897, 0.93394077,\n",
       "        0.12756264, 1.        , 0.88154897, 0.93394077, 0.12756264,\n",
       "        1.        , 0.88154897, 0.93394077, 0.12756264, 1.        ,\n",
       "        0.88838269, 0.94077449, 0.11161731, 0.07972665, 0.88838269,\n",
       "        0.94077449, 0.11161731, 0.07972665, 0.88838269, 0.94077449,\n",
       "        0.11161731, 0.07972665, 0.89977221, 0.88838269, 0.11161731,\n",
       "        1.        , 0.89977221, 0.88838269, 0.11161731, 1.        ,\n",
       "        0.89977221, 0.88838269, 0.11161731, 1.        ]),\n",
       " 'split3_test_specificity': array([0.87927107, 0.93621868, 0.1070615 , 0.        , 0.87927107,\n",
       "        0.93621868, 0.1070615 , 0.        , 0.87927107, 0.93621868,\n",
       "        0.1070615 , 0.        , 0.87927107, 0.92710706, 0.10250569,\n",
       "        0.10022779, 0.87927107, 0.92710706, 0.10250569, 0.10022779,\n",
       "        0.87927107, 0.92710706, 0.10250569, 0.10022779, 0.87699317,\n",
       "        0.92710706, 0.10250569, 0.        , 0.87699317, 0.92710706,\n",
       "        0.10250569, 0.        , 0.87699317, 0.92710706, 0.10250569,\n",
       "        0.        , 0.87471526, 0.92255125, 0.1070615 , 0.        ,\n",
       "        0.87471526, 0.92255125, 0.1070615 , 0.        , 0.87471526,\n",
       "        0.92255125, 0.1070615 , 0.        , 0.88382688, 0.95216401,\n",
       "        0.09567198, 1.        , 0.88382688, 0.95216401, 0.09567198,\n",
       "        1.        , 0.88382688, 0.95216401, 0.09567198, 1.        ,\n",
       "        0.90205011, 0.8405467 , 0.07289294, 1.        , 0.90205011,\n",
       "        0.8405467 , 0.07289294, 1.        , 0.90205011, 0.8405467 ,\n",
       "        0.07289294, 1.        , 0.81321185, 0.85421412, 0.07289294,\n",
       "        0.07289294, 0.81321185, 0.85421412, 0.07289294, 0.07289294,\n",
       "        0.81321185, 0.85421412, 0.07289294, 0.07289294]),\n",
       " 'split4_test_specificity': array([0.92710706, 0.95899772, 0.12756264, 0.0022779 , 0.92710706,\n",
       "        0.95899772, 0.12756264, 0.0022779 , 0.92710706, 0.95899772,\n",
       "        0.12756264, 0.0022779 , 0.92710706, 0.96127563, 0.12756264,\n",
       "        0.0022779 , 0.92710706, 0.96127563, 0.12756264, 0.0022779 ,\n",
       "        0.92710706, 0.96127563, 0.12756264, 0.0022779 , 0.91571754,\n",
       "        0.96127563, 0.12756264, 0.        , 0.91571754, 0.96127563,\n",
       "        0.12756264, 0.        , 0.91571754, 0.96127563, 0.12756264,\n",
       "        0.        , 0.92255125, 0.96355353, 0.13211845, 0.        ,\n",
       "        0.92255125, 0.96355353, 0.13211845, 0.        , 0.92255125,\n",
       "        0.96355353, 0.13211845, 0.        , 0.92482916, 0.95899772,\n",
       "        0.13667426, 0.        , 0.92482916, 0.95899772, 0.13667426,\n",
       "        0.        , 0.92482916, 0.95899772, 0.13667426, 0.        ,\n",
       "        0.90432802, 0.89749431, 0.12756264, 0.        , 0.90432802,\n",
       "        0.89749431, 0.12756264, 0.        , 0.90432802, 0.89749431,\n",
       "        0.12756264, 0.        , 0.8428246 , 0.90660592, 0.12528474,\n",
       "        0.10022779, 0.8428246 , 0.90660592, 0.12528474, 0.10022779,\n",
       "        0.8428246 , 0.90660592, 0.12528474, 0.10022779]),\n",
       " 'mean_test_specificity': array([0.89066059, 0.9476082 , 0.11207289, 0.20045558, 0.89066059,\n",
       "        0.9476082 , 0.11207289, 0.20045558, 0.89066059, 0.9476082 ,\n",
       "        0.11207289, 0.20045558, 0.89066059, 0.94715262, 0.11161731,\n",
       "        0.02687927, 0.89066059, 0.94715262, 0.11161731, 0.02687927,\n",
       "        0.89066059, 0.94715262, 0.11161731, 0.02687927, 0.88792711,\n",
       "        0.94578588, 0.11571754, 0.2       , 0.88792711, 0.94578588,\n",
       "        0.11571754, 0.2       , 0.88792711, 0.94578588, 0.11571754,\n",
       "        0.2       , 0.89749431, 0.94715262, 0.11480638, 0.2       ,\n",
       "        0.89749431, 0.94715262, 0.11480638, 0.2       , 0.89749431,\n",
       "        0.94715262, 0.11480638, 0.2       , 0.89703872, 0.95079727,\n",
       "        0.1143508 , 0.6       , 0.89703872, 0.95079727, 0.1143508 ,\n",
       "        0.6       , 0.89703872, 0.95079727, 0.1143508 , 0.6       ,\n",
       "        0.8952164 , 0.90660592, 0.10387244, 0.41640091, 0.8952164 ,\n",
       "        0.90660592, 0.10387244, 0.41640091, 0.8952164 , 0.90660592,\n",
       "        0.10387244, 0.41640091, 0.861959  , 0.8952164 , 0.09703872,\n",
       "        0.43553531, 0.861959  , 0.8952164 , 0.09703872, 0.43553531,\n",
       "        0.861959  , 0.8952164 , 0.09703872, 0.43553531]),\n",
       " 'std_test_specificity': array([0.03166205, 0.01440673, 0.00904302, 0.39977318, 0.03166205,\n",
       "        0.01440673, 0.00904302, 0.39977318, 0.03166205, 0.01440673,\n",
       "        0.00904302, 0.39977318, 0.03166205, 0.01606851, 0.00922481,\n",
       "        0.03752394, 0.03166205, 0.01606851, 0.00922481, 0.03752394,\n",
       "        0.03166205, 0.01606851, 0.00922481, 0.03752394, 0.02943349,\n",
       "        0.01688725, 0.01100961, 0.4       , 0.02943349, 0.01688725,\n",
       "        0.01100961, 0.4       , 0.02943349, 0.01688725, 0.01100961,\n",
       "        0.4       , 0.04242043, 0.01638825, 0.01014627, 0.4       ,\n",
       "        0.04242043, 0.01638825, 0.01014627, 0.4       , 0.04242043,\n",
       "        0.01638825, 0.01014627, 0.4       , 0.04183909, 0.00972855,\n",
       "        0.01567622, 0.48989795, 0.04183909, 0.00972855, 0.01567622,\n",
       "        0.48989795, 0.04183909, 0.00972855, 0.01567622, 0.48989795,\n",
       "        0.00789089, 0.03638948, 0.01814333, 0.47737049, 0.00789089,\n",
       "        0.03638948, 0.01814333, 0.47737049, 0.00789089, 0.03638948,\n",
       "        0.01814333, 0.47737049, 0.03252222, 0.02250403, 0.02243938,\n",
       "        0.46193608, 0.03252222, 0.02250403, 0.02243938, 0.46193608,\n",
       "        0.03252222, 0.02250403, 0.02243938, 0.46193608]),\n",
       " 'rank_test_specificity': array([31,  4, 70, 52, 31,  4, 70, 52, 31,  4, 70, 52, 31,  7, 73, 82, 31,\n",
       "         7, 73, 82, 31,  7, 73, 82, 37, 13, 61, 55, 37, 13, 61, 55, 37, 13,\n",
       "        61, 55, 19,  7, 64, 55, 19,  7, 64, 55, 19,  7, 64, 55, 22,  1, 67,\n",
       "        43, 22,  1, 67, 43, 22,  1, 67, 43, 25, 16, 76, 49, 25, 16, 76, 49,\n",
       "        25, 16, 76, 49, 40, 25, 79, 46, 40, 25, 79, 46, 40, 25, 79, 46],\n",
       "       dtype=int32),\n",
       " 'split0_train_specificity': array([0.83485194, 0.95899772, 0.12015945, 1.        , 0.83485194,\n",
       "        0.95899772, 0.12015945, 1.        , 0.83485194, 0.95899772,\n",
       "        0.12015945, 1.        , 0.83485194, 0.96013667, 0.12015945,\n",
       "        0.02676538, 0.83485194, 0.96013667, 0.12015945, 0.02676538,\n",
       "        0.83485194, 0.96013667, 0.12015945, 0.02676538, 0.83542141,\n",
       "        0.95785877, 0.12129841, 1.        , 0.83542141, 0.95785877,\n",
       "        0.12129841, 1.        , 0.83542141, 0.95785877, 0.12129841,\n",
       "        1.        , 0.83485194, 0.97038724, 0.11845103, 1.        ,\n",
       "        0.83485194, 0.97038724, 0.11845103, 1.        , 0.83485194,\n",
       "        0.97038724, 0.11845103, 1.        , 0.82460137, 0.95216401,\n",
       "        0.1167426 , 0.        , 0.82460137, 0.95216401, 0.1167426 ,\n",
       "        0.        , 0.82460137, 0.95216401, 0.1167426 , 0.        ,\n",
       "        0.87585421, 0.92995444, 0.11788155, 1.        , 0.87585421,\n",
       "        0.92995444, 0.11788155, 1.        , 0.87585421, 0.92995444,\n",
       "        0.11788155, 1.        , 0.84965831, 0.92084282, 0.08143508,\n",
       "        1.        , 0.84965831, 0.92084282, 0.08143508, 1.        ,\n",
       "        0.84965831, 0.92084282, 0.08143508, 1.        ]),\n",
       " 'split1_train_specificity': array([0.90432802, 0.95728929, 0.12756264, 0.        , 0.90432802,\n",
       "        0.95728929, 0.12756264, 0.        , 0.90432802, 0.95728929,\n",
       "        0.12756264, 0.        , 0.90432802, 0.95728929, 0.11958998,\n",
       "        0.        , 0.90432802, 0.95728929, 0.11958998, 0.        ,\n",
       "        0.90432802, 0.95728929, 0.11958998, 0.        , 0.90432802,\n",
       "        0.9595672 , 0.12129841, 0.        , 0.90432802, 0.9595672 ,\n",
       "        0.12129841, 0.        , 0.90432802, 0.9595672 , 0.12129841,\n",
       "        0.        , 0.95501139, 0.95728929, 0.12927107, 0.        ,\n",
       "        0.95501139, 0.95728929, 0.12927107, 0.        , 0.95501139,\n",
       "        0.95728929, 0.12927107, 0.        , 0.95216401, 0.95501139,\n",
       "        0.12528474, 1.        , 0.95216401, 0.95501139, 0.12528474,\n",
       "        1.        , 0.95216401, 0.95501139, 0.12528474, 1.        ,\n",
       "        0.8809795 , 0.92312073, 0.10876993, 0.00113895, 0.8809795 ,\n",
       "        0.92312073, 0.10876993, 0.00113895, 0.8809795 , 0.92312073,\n",
       "        0.10876993, 0.00113895, 0.87699317, 0.89920273, 0.12186788,\n",
       "        0.00113895, 0.87699317, 0.89920273, 0.12186788, 0.00113895,\n",
       "        0.87699317, 0.89920273, 0.12186788, 0.00113895]),\n",
       " 'split2_train_specificity': array([0.90831435, 0.94874715, 0.10592255, 0.        , 0.90831435,\n",
       "        0.94874715, 0.10592255, 0.        , 0.90831435, 0.94874715,\n",
       "        0.10592255, 0.        , 0.90831435, 0.95387244, 0.10250569,\n",
       "        0.00911162, 0.90831435, 0.95387244, 0.10250569, 0.00911162,\n",
       "        0.90831435, 0.95387244, 0.10250569, 0.00911162, 0.90831435,\n",
       "        0.95728929, 0.11161731, 0.        , 0.90831435, 0.95728929,\n",
       "        0.11161731, 0.        , 0.90831435, 0.95728929, 0.11161731,\n",
       "        0.        , 0.90831435, 0.94817768, 0.10820046, 0.        ,\n",
       "        0.90831435, 0.94817768, 0.10820046, 0.        , 0.90831435,\n",
       "        0.94817768, 0.10820046, 0.        , 0.89066059, 0.9595672 ,\n",
       "        0.1070615 , 1.        , 0.89066059, 0.9595672 , 0.1070615 ,\n",
       "        1.        , 0.89066059, 0.9595672 , 0.1070615 , 1.        ,\n",
       "        0.90888383, 0.96127563, 0.09567198, 0.07118451, 0.90888383,\n",
       "        0.96127563, 0.09567198, 0.07118451, 0.90888383, 0.96127563,\n",
       "        0.09567198, 0.07118451, 0.91400911, 0.89009112, 0.09168565,\n",
       "        1.        , 0.91400911, 0.89009112, 0.09168565, 1.        ,\n",
       "        0.91400911, 0.89009112, 0.09168565, 1.        ]),\n",
       " 'split3_train_specificity': array([0.89806378, 0.94931663, 0.12642369, 0.        , 0.89806378,\n",
       "        0.94931663, 0.12642369, 0.        , 0.89806378, 0.94931663,\n",
       "        0.12642369, 0.        , 0.89806378, 0.94248292, 0.12015945,\n",
       "        0.11332574, 0.89806378, 0.94248292, 0.12015945, 0.11332574,\n",
       "        0.89806378, 0.94248292, 0.12015945, 0.11332574, 0.89806378,\n",
       "        0.93394077, 0.12471526, 0.00170843, 0.89806378, 0.93394077,\n",
       "        0.12471526, 0.00170843, 0.89806378, 0.93394077, 0.12471526,\n",
       "        0.00170843, 0.89749431, 0.93223235, 0.12471526, 0.00455581,\n",
       "        0.89749431, 0.93223235, 0.12471526, 0.00455581, 0.89749431,\n",
       "        0.93223235, 0.12471526, 0.00455581, 0.91059226, 0.9618451 ,\n",
       "        0.1070615 , 1.        , 0.91059226, 0.9618451 , 0.1070615 ,\n",
       "        1.        , 0.91059226, 0.9618451 , 0.1070615 , 1.        ,\n",
       "        0.92369021, 0.87300683, 0.0905467 , 1.        , 0.92369021,\n",
       "        0.87300683, 0.0905467 , 1.        , 0.92369021, 0.87300683,\n",
       "        0.0905467 , 1.        , 0.85193622, 0.8809795 , 0.0905467 ,\n",
       "        0.08997722, 0.85193622, 0.8809795 , 0.0905467 , 0.08997722,\n",
       "        0.85193622, 0.8809795 , 0.0905467 , 0.08997722]),\n",
       " 'split4_train_specificity': array([9.29384966e-01, 9.73234624e-01, 1.09339408e-01, 4.55580866e-03,\n",
       "        9.29384966e-01, 9.73234624e-01, 1.09339408e-01, 4.55580866e-03,\n",
       "        9.29384966e-01, 9.73234624e-01, 1.09339408e-01, 4.55580866e-03,\n",
       "        9.29384966e-01, 9.72665148e-01, 1.08769932e-01, 3.98633257e-03,\n",
       "        9.29384966e-01, 9.72665148e-01, 1.08769932e-01, 3.98633257e-03,\n",
       "        9.29384966e-01, 9.72665148e-01, 1.08769932e-01, 3.98633257e-03,\n",
       "        9.26537585e-01, 9.72095672e-01, 1.07061503e-01, 0.00000000e+00,\n",
       "        9.26537585e-01, 9.72095672e-01, 1.07061503e-01, 0.00000000e+00,\n",
       "        9.26537585e-01, 9.72095672e-01, 1.07061503e-01, 0.00000000e+00,\n",
       "        9.25398633e-01, 9.71526196e-01, 1.09908884e-01, 0.00000000e+00,\n",
       "        9.25398633e-01, 9.71526196e-01, 1.09908884e-01, 0.00000000e+00,\n",
       "        9.25398633e-01, 9.71526196e-01, 1.09908884e-01, 0.00000000e+00,\n",
       "        9.30523918e-01, 9.68109339e-01, 1.16173121e-01, 5.69476082e-04,\n",
       "        9.30523918e-01, 9.68109339e-01, 1.16173121e-01, 5.69476082e-04,\n",
       "        9.30523918e-01, 9.68109339e-01, 1.16173121e-01, 5.69476082e-04,\n",
       "        9.07175399e-01, 9.08883827e-01, 1.02505695e-01, 2.27790433e-03,\n",
       "        9.07175399e-01, 9.08883827e-01, 1.02505695e-01, 2.27790433e-03,\n",
       "        9.07175399e-01, 9.08883827e-01, 1.02505695e-01, 2.27790433e-03,\n",
       "        8.61617312e-01, 9.19134396e-01, 1.02505695e-01, 8.65603645e-02,\n",
       "        8.61617312e-01, 9.19134396e-01, 1.02505695e-01, 8.65603645e-02,\n",
       "        8.61617312e-01, 9.19134396e-01, 1.02505695e-01, 8.65603645e-02]),\n",
       " 'mean_train_specificity': array([0.89498861, 0.95751708, 0.11788155, 0.20091116, 0.89498861,\n",
       "        0.95751708, 0.11788155, 0.20091116, 0.89498861, 0.95751708,\n",
       "        0.11788155, 0.20091116, 0.89498861, 0.95728929, 0.1142369 ,\n",
       "        0.03063781, 0.89498861, 0.95728929, 0.1142369 , 0.03063781,\n",
       "        0.89498861, 0.95728929, 0.1142369 , 0.03063781, 0.89453303,\n",
       "        0.95615034, 0.11719818, 0.20034169, 0.89453303, 0.95615034,\n",
       "        0.11719818, 0.20034169, 0.89453303, 0.95615034, 0.11719818,\n",
       "        0.20034169, 0.90421412, 0.95592255, 0.11810934, 0.20091116,\n",
       "        0.90421412, 0.95592255, 0.11810934, 0.20091116, 0.90421412,\n",
       "        0.95592255, 0.11810934, 0.20091116, 0.90170843, 0.95933941,\n",
       "        0.11446469, 0.6001139 , 0.90170843, 0.95933941, 0.11446469,\n",
       "        0.6001139 , 0.90170843, 0.95933941, 0.11446469, 0.6001139 ,\n",
       "        0.89931663, 0.91924829, 0.10307517, 0.41492027, 0.89931663,\n",
       "        0.91924829, 0.10307517, 0.41492027, 0.89931663, 0.91924829,\n",
       "        0.10307517, 0.41492027, 0.87084282, 0.90205011, 0.0976082 ,\n",
       "        0.43553531, 0.87084282, 0.90205011, 0.0976082 , 0.43553531,\n",
       "        0.87084282, 0.90205011, 0.0976082 , 0.43553531]),\n",
       " 'std_train_specificity': array([0.03185525, 0.00887068, 0.00880757, 0.39954832, 0.03185525,\n",
       "        0.00887068, 0.00880757, 0.39954832, 0.03185525, 0.00887068,\n",
       "        0.00880757, 0.39954832, 0.03185525, 0.00975119, 0.00729819,\n",
       "        0.04234299, 0.03185525, 0.00975119, 0.00729819, 0.04234299,\n",
       "        0.03185525, 0.00975119, 0.00729819, 0.04234299, 0.03103807,\n",
       "        0.01235645, 0.00669371, 0.3998297 , 0.03103807, 0.01235645,\n",
       "        0.00669371, 0.3998297 , 0.03103807, 0.01235645, 0.00669371,\n",
       "        0.3998297 , 0.03975481, 0.01466818, 0.00817034, 0.39954832,\n",
       "        0.03975481, 0.01466818, 0.00817034, 0.39954832, 0.03975481,\n",
       "        0.01466818, 0.00817034, 0.39954832, 0.04364075, 0.00554004,\n",
       "        0.00685267, 0.48975849, 0.04364075, 0.00554004, 0.00685267,\n",
       "        0.48975849, 0.04364075, 0.00554004, 0.00685267, 0.48975849,\n",
       "        0.01807815, 0.02878058, 0.00963071, 0.47838887, 0.01807815,\n",
       "        0.02878058, 0.00963071, 0.47838887, 0.01807815, 0.02878058,\n",
       "        0.00963071, 0.47838887, 0.02363264, 0.01574887, 0.0138494 ,\n",
       "        0.46198157, 0.02363264, 0.01574887, 0.0138494 , 0.46198157,\n",
       "        0.02363264, 0.01574887, 0.0138494 , 0.46198157])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f693d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__activation': 'logistic',\n",
       " 'classifier__alpha': 1,\n",
       " 'classifier__early_stopping': True,\n",
       " 'classifier__hidden_layer_sizes': (150, 150),\n",
       " 'classifier__learning_rate': 'constant',\n",
       " 'classifier__learning_rate_init': 0.001}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66a2b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/04/28 11:56:54 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"e1c5428339bb4ec5ae1e6319bb200628\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22120 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Registered model 'mlp_gridsearch' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'mlp_gridsearch'.\n"
     ]
    }
   ],
   "source": [
    "# Convertimos los resultados de la validación cruzada en un dataframe\n",
    "df_results = pd.DataFrame(grid_search.cv_results_)\n",
    "df_results\n",
    "\n",
    "# Filtrando la fila con condiciones específicas\n",
    "filtered_row = df_results.loc[\n",
    "    (df_results['param_classifier__activation'] == 'logistic') &\n",
    "    (df_results['param_classifier__alpha'] == 1) &\n",
    "    (df_results['param_classifier__early_stopping'] == True) &\n",
    "    (df_results['param_classifier__hidden_layer_sizes'] == (150, 150)) &\n",
    "    (df_results['param_classifier__learning_rate'] == 'constant') &\n",
    "    (df_results['param_classifier__learning_rate_init'] == 0.001)\n",
    "]\n",
    "\n",
    "index_row = filtered_row.index[0]\n",
    "\n",
    "# Registro los resultados en MLFlow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Almaceno los valores de los hiperparámetros\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    # Registra las métricas de cada fold para cada métrica\n",
    "    for metric in METRICS.keys():\n",
    "        \n",
    "        # Media\n",
    "        mlflow.log_metric(f\"mean_train_{metric}\", df_results[f\"mean_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"mean_test_{metric}\", df_results[f\"mean_test_{metric}\"][index_row])\n",
    "\n",
    "        # Desviación típica\n",
    "        mlflow.log_metric(f\"std_train_{metric}\", df_results[f\"std_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"std_test_{metric}\", df_results[f\"std_test_{metric}\"][index_row])\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            # Resultados de entrenamiento en cada fold\n",
    "            mlflow.log_metric(f\"train_{metric}fold{i}\", df_results[f\"split{i}_train_{metric}\"][index_row])\n",
    "            # Resultados de validación en cada fold\n",
    "            mlflow.log_metric(f\"test_{metric}fold{i}\", df_results[f\"split{i}_test_{metric}\"][index_row])\n",
    "\n",
    "    # Establece una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"GridSearch 84 combinaciones. sinfic\")\n",
    "\n",
    "    # Infiere el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    signature = infer_signature(X_scaled_train, grid_search.best_estimator_.predict(X_scaled_train))\n",
    "\n",
    "    # Registra el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=grid_search,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_scaled_train,\n",
    "        registered_model_name=\"mlp_gridsearch\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873ebb69",
   "metadata": {},
   "source": [
    "### 2.2 Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d635a",
   "metadata": {},
   "source": [
    "[RandomizedSearchCV - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "Con esta estrategia podemos aprovechar un rango más amplio de posibles hiperparámetros sin comprometer la capacidad computacional, ya que coge un número fijo (`n_iter`) de combinaciones aleatorias dentro de los rangos establecidos. \n",
    "\n",
    "Para beneficiarnos más de esta técnica y aumentar la variedad, vamos a presentar los posibles valores de los parámetros continuos como distribuciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "582bf9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12e9e93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    }
   ],
   "source": [
    "# Defino las distribuciones de los parámetros\n",
    "param_dist = {\n",
    "    'classifier__hidden_layer_sizes': [LAYERS],\n",
    "    'classifier__activation': ['logistic'],\n",
    "    'classifier__early_stopping': [True],\n",
    "    'classifier__alpha': uniform(0.00001, 1),\n",
    "    'classifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'classifier__learning_rate_init': uniform(0.0001, 0.1)\n",
    "}\n",
    "\n",
    "# Inicializo RandomizedSearch\n",
    "N_ITER = 84\n",
    "random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=N_ITER, cv=kf,\n",
    "                                    scoring=METRICS, return_train_score=True,\n",
    "                                    refit=\"balanced_accuracy\",\n",
    "                                    verbose=1, n_jobs=-1)\n",
    "\n",
    "random_search.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "# Resultados\n",
    "cv_results_rand = random_search.cv_results_\n",
    "best_params_rand = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8953f188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([11.56951537,  9.10348473,  9.87192369,  9.3142827 , 10.06285415,\n",
       "         9.76468039,  9.45027752,  8.35551071,  7.47671847,  9.69924817,\n",
       "         8.26404824,  7.62778144,  9.96234946,  7.95484653,  8.2268074 ,\n",
       "         7.75106978,  7.73968673,  7.71264849,  8.8409626 ,  8.16882863,\n",
       "         7.58212376,  7.94431324,  7.82593765,  8.05413828,  8.16997652,\n",
       "         8.19563632,  7.99102759,  8.22263675,  7.94842858,  7.95001249,\n",
       "         8.51812215,  8.35831895,  8.01961803,  7.65736151,  8.56740012,\n",
       "         8.76795511,  7.74659534,  8.29305372,  7.89078803,  8.19654956,\n",
       "         8.60006304,  7.99725943,  8.12159801,  7.91562724,  8.48831587,\n",
       "         8.17407675,  7.87400079,  8.47872372,  8.20798416, 11.00647206,\n",
       "         8.45372205,  8.82169304,  8.45829201,  8.31176395,  9.02223177,\n",
       "        10.05631309,  8.11710863,  8.13685284,  8.04384379,  7.94366879,\n",
       "         8.05411563,  8.22297487,  9.09068542,  8.12298808,  8.24290934,\n",
       "         8.31779723,  8.23348989,  8.67965026,  8.06361461,  8.36223674,\n",
       "         8.30864072,  8.12135553,  8.27003489,  8.54765515,  8.60101767,\n",
       "         8.2393055 ,  8.23867278,  8.50067644,  8.98846035,  8.30904346,\n",
       "         9.23574734,  8.57372227,  8.55493002,  7.96547899]),\n",
       " 'std_fit_time': array([1.10909234, 0.74388193, 0.32297326, 0.44275725, 0.97126548,\n",
       "        0.87742863, 0.38918043, 0.52032991, 0.13525175, 0.7502347 ,\n",
       "        0.39114704, 0.09537423, 0.62890235, 0.8449992 , 0.33683136,\n",
       "        0.05947418, 0.24582546, 0.32903684, 0.70645248, 0.24687324,\n",
       "        0.13899179, 0.16208087, 0.22579672, 0.27518562, 0.26999889,\n",
       "        0.20144212, 0.13413867, 0.45065779, 0.23269771, 0.06433657,\n",
       "        0.94346572, 0.40390862, 0.24873714, 0.36681428, 0.64248098,\n",
       "        0.82324565, 0.21400031, 0.3452848 , 0.289376  , 0.06847475,\n",
       "        0.92602203, 0.33760274, 0.17861303, 0.37997436, 0.3094817 ,\n",
       "        0.59335847, 0.34190566, 0.11477502, 0.42579865, 1.18204108,\n",
       "        0.43373055, 1.03147939, 0.39771425, 0.68919081, 0.7671165 ,\n",
       "        0.72587087, 0.14879995, 0.19091625, 0.26690071, 0.18000611,\n",
       "        0.26333198, 0.31549732, 0.51324258, 0.17087615, 0.09583552,\n",
       "        0.1281017 , 0.29386844, 0.31825859, 0.19319246, 0.67381555,\n",
       "        0.06023122, 0.12748783, 0.18637121, 0.55858089, 0.24165036,\n",
       "        0.08327321, 0.30474414, 0.13221003, 0.98645101, 0.15350556,\n",
       "        0.44914913, 1.06119816, 0.25865509, 0.12474693]),\n",
       " 'mean_score_time': array([0.01226602, 0.01509218, 0.01601076, 0.01319504, 0.00967021,\n",
       "        0.01161137, 0.0143846 , 0.01210999, 0.01126857, 0.00982385,\n",
       "        0.01357455, 0.01306443, 0.01699166, 0.01342254, 0.0105907 ,\n",
       "        0.01291842, 0.00995984, 0.01230412, 0.0109581 , 0.01210098,\n",
       "        0.0104054 , 0.01181836, 0.01057491, 0.01072869, 0.01618266,\n",
       "        0.01117387, 0.0122416 , 0.01484084, 0.01345582, 0.01106405,\n",
       "        0.00946226, 0.01615982, 0.00885196, 0.01349297, 0.01584401,\n",
       "        0.01200557, 0.01210375, 0.01435633, 0.0108994 , 0.01203299,\n",
       "        0.01192074, 0.01105647, 0.01396575, 0.01200757, 0.01175046,\n",
       "        0.01348925, 0.01705465, 0.01451483, 0.01603947, 0.0109262 ,\n",
       "        0.01398063, 0.01416874, 0.01325083, 0.01272783, 0.01139798,\n",
       "        0.01310682, 0.01086712, 0.01174607, 0.01210856, 0.01172628,\n",
       "        0.01348205, 0.01439576, 0.01300497, 0.01242476, 0.01094785,\n",
       "        0.01312976, 0.01278167, 0.01354632, 0.01200995, 0.01402783,\n",
       "        0.01242762, 0.01472764, 0.01112781, 0.01121554, 0.01189513,\n",
       "        0.00963058, 0.0131217 , 0.01611772, 0.0139739 , 0.01565452,\n",
       "        0.01485167, 0.01075435, 0.01486883, 0.01077509]),\n",
       " 'std_score_time': array([0.00288352, 0.0025195 , 0.00490484, 0.00478752, 0.00286996,\n",
       "        0.00368841, 0.00655984, 0.0028329 , 0.00447289, 0.00251236,\n",
       "        0.00247308, 0.00275641, 0.00296524, 0.0050878 , 0.00251077,\n",
       "        0.00435149, 0.002376  , 0.00222192, 0.00393462, 0.00194757,\n",
       "        0.00257612, 0.00351828, 0.00357448, 0.00292027, 0.00613278,\n",
       "        0.00267376, 0.00468004, 0.00513947, 0.00494791, 0.00330806,\n",
       "        0.00156706, 0.00558655, 0.00101295, 0.00349394, 0.0063007 ,\n",
       "        0.00515909, 0.0022609 , 0.00450601, 0.0038515 , 0.00289706,\n",
       "        0.00222813, 0.00200598, 0.00209044, 0.00261319, 0.00320606,\n",
       "        0.00422984, 0.00619194, 0.00428627, 0.00556958, 0.00284823,\n",
       "        0.00238636, 0.000754  , 0.00445295, 0.00165882, 0.00231408,\n",
       "        0.00281902, 0.00293851, 0.00354613, 0.00240534, 0.00436112,\n",
       "        0.00215277, 0.00548366, 0.00234961, 0.00339917, 0.00220493,\n",
       "        0.00256533, 0.00121517, 0.00429106, 0.00279637, 0.00350076,\n",
       "        0.00408657, 0.00444579, 0.00350734, 0.00311919, 0.00256929,\n",
       "        0.0017947 , 0.00317417, 0.00372474, 0.00082364, 0.00378019,\n",
       "        0.00410869, 0.00205479, 0.00356437, 0.0026813 ]),\n",
       " 'param_classifier__activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__alpha': masked_array(data=[0.20193091842294003, 0.19407571036333954,\n",
       "                    0.8435429341871563, 0.6841667475546377,\n",
       "                    0.6010318525915526, 0.6184676955101834,\n",
       "                    0.4629130010433123, 0.846545888238137,\n",
       "                    0.2012240954338907, 0.21509037625637845,\n",
       "                    0.9321483489101262, 0.2967293103413639,\n",
       "                    0.8773407884629941, 0.794972038543066,\n",
       "                    0.9068763236116857, 0.17238458211678126,\n",
       "                    0.3983964573134991, 0.14891497486100364,\n",
       "                    0.6528818164261545, 0.07197857153302804,\n",
       "                    0.3743125904983285, 0.4345306605827089,\n",
       "                    0.1786936247395488, 0.04686991131522527,\n",
       "                    0.928896438851447, 0.3369039705863985,\n",
       "                    0.9828608011281589, 0.38988869803348064,\n",
       "                    0.1507802289749875, 0.40989913239669035,\n",
       "                    0.00869912541031952, 0.9950735526164837,\n",
       "                    0.13877368913271454, 0.18355927879499495,\n",
       "                    0.1972997509773297, 0.7985487586102031,\n",
       "                    0.46703186512970013, 0.4820237587738336,\n",
       "                    0.2301556528826489, 0.6223969743566273,\n",
       "                    0.9554534027196419, 0.5855535564517964,\n",
       "                    0.1005875787246066, 0.04801505834267122,\n",
       "                    0.8208088825539198, 0.9557625488563187,\n",
       "                    0.02282161589939562, 0.5844003842181096,\n",
       "                    0.7401344918954148, 0.8790061982074505,\n",
       "                    0.18601192083938373, 0.7666898251854419,\n",
       "                    0.9872254459849132, 0.8771634124244982,\n",
       "                    0.5091466231425066, 0.16542611785073685,\n",
       "                    0.7314301116211447, 0.0992149051626217,\n",
       "                    0.4406499980356779, 0.47808635587654585,\n",
       "                    0.8528985832703645, 0.29840552177743324,\n",
       "                    0.057862092232940636, 0.05102203028562429,\n",
       "                    0.25857566373422586, 0.2152958555152618,\n",
       "                    0.466989626159034, 0.7343237277543939,\n",
       "                    0.8906544466652299, 0.5135280399325833,\n",
       "                    0.5283379169310986, 0.14528297074169666,\n",
       "                    0.34910406871370586, 0.8299249470701212,\n",
       "                    0.7811062906116034, 0.23139716585105857,\n",
       "                    0.43715514202124767, 0.42187767338395704,\n",
       "                    0.41214978963129717, 0.25146031862297097,\n",
       "                    0.8862321098843323, 0.6369807544121776,\n",
       "                    0.2706434207005513, 0.09208912605952661],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True, True, True, True, True, True, True,\n",
       "                    True, True, True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__hidden_layer_sizes': masked_array(data=[(150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150),\n",
       "                    (150, 150), (150, 150), (150, 150), (150, 150)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__learning_rate': masked_array(data=['adaptive', 'constant', 'adaptive', 'adaptive',\n",
       "                    'invscaling', 'adaptive', 'invscaling', 'constant',\n",
       "                    'constant', 'adaptive', 'invscaling', 'constant',\n",
       "                    'adaptive', 'constant', 'constant', 'constant',\n",
       "                    'adaptive', 'constant', 'constant', 'constant',\n",
       "                    'adaptive', 'invscaling', 'constant', 'adaptive',\n",
       "                    'constant', 'adaptive', 'constant', 'invscaling',\n",
       "                    'constant', 'adaptive', 'invscaling', 'constant',\n",
       "                    'adaptive', 'invscaling', 'adaptive', 'invscaling',\n",
       "                    'invscaling', 'adaptive', 'invscaling', 'adaptive',\n",
       "                    'invscaling', 'adaptive', 'constant', 'constant',\n",
       "                    'invscaling', 'invscaling', 'invscaling', 'invscaling',\n",
       "                    'constant', 'invscaling', 'invscaling', 'constant',\n",
       "                    'invscaling', 'invscaling', 'constant', 'adaptive',\n",
       "                    'adaptive', 'invscaling', 'invscaling', 'constant',\n",
       "                    'invscaling', 'invscaling', 'constant', 'invscaling',\n",
       "                    'invscaling', 'constant', 'invscaling', 'invscaling',\n",
       "                    'adaptive', 'invscaling', 'adaptive', 'constant',\n",
       "                    'adaptive', 'adaptive', 'adaptive', 'invscaling',\n",
       "                    'constant', 'invscaling', 'constant', 'constant',\n",
       "                    'constant', 'invscaling', 'adaptive', 'adaptive'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_classifier__learning_rate_init': masked_array(data=[0.002509283948712648, 0.06820813947543669,\n",
       "                    0.09222328430092129, 0.09483811594418383,\n",
       "                    0.07347683449004443, 0.06518625363627054,\n",
       "                    0.07280926626635786, 0.05783690349563493,\n",
       "                    0.07232947761124184, 0.0025700917793795683,\n",
       "                    0.0662137402230987, 0.08015474203282301,\n",
       "                    0.0023019050769459534, 0.08195854766863594,\n",
       "                    0.0725498678956986, 0.03956010135748553,\n",
       "                    0.06014974599917991, 0.02904494571795282,\n",
       "                    0.012029171258552662, 0.09202838980769762,\n",
       "                    0.07773132212730484, 0.0608474521377482,\n",
       "                    0.08280399563214574, 0.0998521450910079,\n",
       "                    0.014093009251365718, 0.018162718848259696,\n",
       "                    0.09029572793814997, 0.05742951564390324,\n",
       "                    0.08300662311037268, 0.04877896997123206,\n",
       "                    0.005999967671869566, 0.01391659074688385,\n",
       "                    0.05045637159522433, 0.07235795475352184,\n",
       "                    0.013101360951927588, 0.07360557686951985,\n",
       "                    0.04989904931091426, 0.06222918801905805,\n",
       "                    0.06699505182502631, 0.04655269964617316,\n",
       "                    0.013481249082982382, 0.05900339339075784,\n",
       "                    0.0797606397519875, 0.08261030365358826,\n",
       "                    0.08109269280625298, 0.08942296198080434,\n",
       "                    0.05922851258496419, 0.07354176087386444,\n",
       "                    0.07534109035628057, 0.004116558284492433,\n",
       "                    0.0923413767754058, 0.07247273618906169,\n",
       "                    0.034223846330678445, 0.05708094241686122,\n",
       "                    0.012574960431371096, 0.0026352250851977787,\n",
       "                    0.06584175200091674, 0.0607147467868666,\n",
       "                    0.061742224704540286, 0.02502194435837306,\n",
       "                    0.08648550444702316, 0.07887975248118918,\n",
       "                    0.01180037698525761, 0.05523747516980046,\n",
       "                    0.09555334926694577, 0.041768540037489706,\n",
       "                    0.03439410535497673, 0.03595478643284777,\n",
       "                    0.047410271016028224, 0.033084202831184475,\n",
       "                    0.049347091617416676, 0.052144161491182714,\n",
       "                    0.02621075657807701, 0.04523160988156672,\n",
       "                    0.06521487525799975, 0.07905759015493354,\n",
       "                    0.0629666546727694, 0.07030241742308625,\n",
       "                    0.030559917174405937, 0.08438171811870919,\n",
       "                    0.04298455919010699, 0.07314925094732222,\n",
       "                    0.07543985272419652, 0.04087293491516618],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.20193091842294003,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.002509283948712648},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.19407571036333954,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.06820813947543669},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8435429341871563,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.09222328430092129},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6841667475546377,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.09483811594418383},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6010318525915526,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07347683449004443},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6184676955101834,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.06518625363627054},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.4629130010433123,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07280926626635786},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.846545888238137,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.05783690349563493},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.2012240954338907,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.07232947761124184},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.21509037625637845,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0025700917793795683},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9321483489101262,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0662137402230987},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.2967293103413639,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08015474203282301},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8773407884629941,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0023019050769459534},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.794972038543066,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08195854766863594},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9068763236116857,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0725498678956986},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.17238458211678126,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.03956010135748553},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.3983964573134991,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.06014974599917991},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.14891497486100364,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.02904494571795282},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6528818164261545,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.012029171258552662},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.07197857153302804,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.09202838980769762},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.3743125904983285,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.07773132212730484},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.4345306605827089,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0608474521377482},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1786936247395488,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08280399563214574},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.04686991131522527,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0998521450910079},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.928896438851447,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.014093009251365718},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.3369039705863985,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.018162718848259696},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9828608011281589,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.09029572793814997},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.38988869803348064,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.05742951564390324},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1507802289749875,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08300662311037268},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.40989913239669035,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.04877896997123206},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.00869912541031952,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.005999967671869566},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9950735526164837,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01391659074688385},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.13877368913271454,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.05045637159522433},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.18355927879499495,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07235795475352184},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1972997509773297,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.013101360951927588},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7985487586102031,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07360557686951985},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.46703186512970013,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.04989904931091426},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.4820237587738336,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.06222918801905805},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.2301556528826489,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.06699505182502631},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6223969743566273,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.04655269964617316},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9554534027196419,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.013481249082982382},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5855535564517964,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.05900339339075784},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.1005875787246066,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0797606397519875},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.04801505834267122,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08261030365358826},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8208088825539198,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.08109269280625298},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9557625488563187,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.08942296198080434},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.02282161589939562,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.05922851258496419},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5844003842181096,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07354176087386444},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7401344918954148,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.07534109035628057},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8790061982074505,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.004116558284492433},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.18601192083938373,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0923413767754058},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7666898251854419,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.07247273618906169},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.9872254459849132,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.034223846330678445},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8771634124244982,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.05708094241686122},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5091466231425066,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.012574960431371096},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.16542611785073685,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.0026352250851977787},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7314301116211447,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.06584175200091674},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.0992149051626217,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.0607147467868666},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.4406499980356779,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.061742224704540286},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.47808635587654585,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.02502194435837306},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8528985832703645,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.08648550444702316},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.29840552177743324,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07887975248118918},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.057862092232940636,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.01180037698525761},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.05102203028562429,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.05523747516980046},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.25857566373422586,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.09555334926694577},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.2152958555152618,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.041768540037489706},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.466989626159034,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.03439410535497673},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7343237277543939,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.03595478643284777},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8906544466652299,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.047410271016028224},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5135280399325833,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.033084202831184475},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.5283379169310986,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.049347091617416676},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.14528297074169666,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.052144161491182714},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.34910406871370586,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.02621075657807701},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8299249470701212,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.04523160988156672},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.7811062906116034,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.06521487525799975},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.23139716585105857,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07905759015493354},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.43715514202124767,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.0629666546727694},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.42187767338395704,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07030241742308625},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.41214978963129717,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.030559917174405937},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.25146031862297097,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.08438171811870919},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.8862321098843323,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'constant',\n",
       "   'classifier__learning_rate_init': 0.04298455919010699},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.6369807544121776,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'invscaling',\n",
       "   'classifier__learning_rate_init': 0.07314925094732222},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.2706434207005513,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.07543985272419652},\n",
       "  {'classifier__activation': 'logistic',\n",
       "   'classifier__alpha': 0.09208912605952661,\n",
       "   'classifier__early_stopping': True,\n",
       "   'classifier__hidden_layer_sizes': (150, 150),\n",
       "   'classifier__learning_rate': 'adaptive',\n",
       "   'classifier__learning_rate_init': 0.04087293491516618}],\n",
       " 'split0_test_balanced_accuracy': array([0.8487036 , 0.5       , 0.5       , 0.5       , 0.51138952,\n",
       "        0.5       , 0.5       , 0.5       , 0.50113895, 0.81825338,\n",
       "        0.52164009, 0.5       , 0.85771473, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5022779 , 0.54441913, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.54100228,\n",
       "        0.5       , 0.5       , 0.5       , 0.50113895, 0.50113895,\n",
       "        0.51904395, 0.5284738 , 0.5       , 0.5       , 0.54617781,\n",
       "        0.5       , 0.51025057, 0.5       , 0.5       , 0.5       ,\n",
       "        0.52164009, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50113895, 0.5       , 0.5       , 0.5       , 0.55125285,\n",
       "        0.5       , 0.53189066, 0.5       , 0.52164009, 0.55125285,\n",
       "        0.82892269, 0.5       , 0.50113895, 0.5       , 0.5       ,\n",
       "        0.5       , 0.50113895, 0.5094131 , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50113895, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.50797267, 0.5       , 0.5       , 0.5       ,\n",
       "        0.52050114, 0.5       , 0.5022779 , 0.51025057]),\n",
       " 'split1_test_balanced_accuracy': array([0.80023114, 0.50569476, 0.5022779 , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.4977221 , 0.78262763,\n",
       "        0.5       , 0.5       , 0.83741458, 0.50911162, 0.54897494,\n",
       "        0.49886105, 0.5       , 0.52277904, 0.53882487, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.50569476, 0.52277904,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.53261088, 0.51594533, 0.5       , 0.4977221 , 0.54389991,\n",
       "        0.54441913, 0.5       , 0.5       , 0.49886105, 0.5       ,\n",
       "        0.51594533, 0.5       , 0.50113895, 0.5       , 0.5       ,\n",
       "        0.50455581, 0.50341686, 0.5       , 0.5       , 0.77081938,\n",
       "        0.5       , 0.5       , 0.51676605, 0.5       , 0.54897494,\n",
       "        0.79339743, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.53075171, 0.51904395, 0.5       , 0.5       ,\n",
       "        0.49886105, 0.5       , 0.53758542, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.53644647, 0.5       ,\n",
       "        0.49886105, 0.5       , 0.5       , 0.5       , 0.51252847,\n",
       "        0.5       , 0.5       , 0.49886105, 0.50341686]),\n",
       " 'split2_test_balanced_accuracy': array([0.79225848, 0.5       , 0.53416856, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.53189066, 0.5       , 0.81535576,\n",
       "        0.55808656, 0.49886105, 0.82384765, 0.5       , 0.5       ,\n",
       "        0.51138952, 0.5       , 0.50455581, 0.55808656, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.55580866,\n",
       "        0.51366743, 0.50113895, 0.49886105, 0.5       , 0.5       ,\n",
       "        0.55073362, 0.53302961, 0.5       , 0.5       , 0.5501139 ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5022779 ,\n",
       "        0.52050114, 0.5022779 , 0.5       , 0.5       , 0.50113895,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.80914177,\n",
       "        0.50569476, 0.5       , 0.5       , 0.5       , 0.56150342,\n",
       "        0.81991156, 0.5       , 0.49886105, 0.5       , 0.5       ,\n",
       "        0.5022779 , 0.5       , 0.55528943, 0.50911162, 0.5       ,\n",
       "        0.5022779 , 0.5261959 , 0.50455581, 0.5       , 0.51025057,\n",
       "        0.5       , 0.5       , 0.5       , 0.4977221 , 0.5       ,\n",
       "        0.5       , 0.5       , 0.49886105, 0.56605923, 0.5       ,\n",
       "        0.52050114, 0.5       , 0.5       , 0.4977221 ]),\n",
       " 'split3_test_balanced_accuracy': array([0.78148868, 0.50455581, 0.50569476, 0.5       , 0.5       ,\n",
       "        0.51252847, 0.5       , 0.5       , 0.5       , 0.79785274,\n",
       "        0.50569476, 0.5       , 0.81847112, 0.5       , 0.53986333,\n",
       "        0.5       , 0.5       , 0.5       , 0.52733485, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.52733485,\n",
       "        0.52277904, 0.5       , 0.50797267, 0.5       , 0.5       ,\n",
       "        0.78532427, 0.54669704, 0.5       , 0.5       , 0.53302961,\n",
       "        0.5261959 , 0.5       , 0.5       , 0.5       , 0.4977221 ,\n",
       "        0.54669704, 0.5       , 0.5       , 0.5       , 0.50569476,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.78294587,\n",
       "        0.5       , 0.5501139 , 0.5       , 0.5       , 0.53189066,\n",
       "        0.77921077, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.54503886, 0.5       , 0.55125285, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.50683371, 0.5       , 0.5       , 0.50341686,\n",
       "        0.5       , 0.5       , 0.5       , 0.53302961, 0.5       ,\n",
       "        0.5       , 0.50569476, 0.5       , 0.5       ]),\n",
       " 'split4_test_balanced_accuracy': array([0.80342026, 0.50113895, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.51594533, 0.5       , 0.74359977,\n",
       "        0.53644647, 0.5       , 0.8189746 , 0.5       , 0.50797267,\n",
       "        0.5       , 0.5       , 0.50113895, 0.56036446, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5284738 , 0.54555809,\n",
       "        0.51366743, 0.50113895, 0.5       , 0.5       , 0.5       ,\n",
       "        0.56605923, 0.50341686, 0.5       , 0.5       , 0.55125285,\n",
       "        0.52164009, 0.5       , 0.5       , 0.5       , 0.51594533,\n",
       "        0.51480638, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.52050114, 0.5       , 0.5       , 0.5       , 0.78672696,\n",
       "        0.5       , 0.5       , 0.51822323, 0.55580866, 0.56150342,\n",
       "        0.73778601, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.56605923, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.50113895, 0.5       , 0.5       ,\n",
       "        0.5       , 0.52277904, 0.50341686, 0.5       , 0.52505695,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.54783599, 0.5       , 0.5       , 0.50113895]),\n",
       " 'mean_test_balanced_accuracy': array([0.80522043, 0.5022779 , 0.50842825, 0.5       , 0.5022779 ,\n",
       "        0.50250569, 0.5       , 0.5095672 , 0.49977221, 0.79153786,\n",
       "        0.52437358, 0.49977221, 0.83128454, 0.50182232, 0.51936219,\n",
       "        0.50205011, 0.5       , 0.50615034, 0.54580598, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.50683371, 0.53849658,\n",
       "        0.51002278, 0.50045558, 0.50136674, 0.50022779, 0.50022779,\n",
       "        0.59075439, 0.52551253, 0.5       , 0.49954442, 0.54489481,\n",
       "        0.51845103, 0.50205011, 0.5       , 0.49977221, 0.50318907,\n",
       "        0.523918  , 0.50045558, 0.50022779, 0.5       , 0.50136674,\n",
       "        0.50523918, 0.50068337, 0.5       , 0.5       , 0.74017736,\n",
       "        0.50113895, 0.51640091, 0.50699786, 0.51548975, 0.55102506,\n",
       "        0.79184569, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50946335, 0.50637813, 0.54021171, 0.50182232, 0.5       ,\n",
       "        0.50022779, 0.50523918, 0.50865604, 0.5       , 0.50205011,\n",
       "        0.50022779, 0.50592255, 0.50068337, 0.50683371, 0.50569476,\n",
       "        0.49977221, 0.50159453, 0.49977221, 0.51981777, 0.50250569,\n",
       "        0.51776765, 0.50113895, 0.50022779, 0.50250569]),\n",
       " 'std_test_balanced_accuracy': array([0.02302229, 0.00238909, 0.01303789, 0.        , 0.00455581,\n",
       "        0.00501139, 0.        , 0.01275626, 0.00111594, 0.02719684,\n",
       "        0.02113178, 0.00045558, 0.01488058, 0.00364465, 0.02086491,\n",
       "        0.00469049, 0.        , 0.00844977, 0.01228498, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01104255, 0.01206214,\n",
       "        0.00883404, 0.00055797, 0.00333229, 0.00045558, 0.00045558,\n",
       "        0.09858195, 0.0147906 , 0.        , 0.00091116, 0.00649742,\n",
       "        0.01688417, 0.00410023, 0.        , 0.00045558, 0.00653882,\n",
       "        0.0116819 , 0.00091116, 0.00045558, 0.        , 0.00220851,\n",
       "        0.00781158, 0.00136674, 0.        , 0.        , 0.09527172,\n",
       "        0.0022779 , 0.02089721, 0.00858297, 0.02183226, 0.01086252,\n",
       "        0.03239412, 0.        , 0.00072034, 0.        , 0.        ,\n",
       "        0.01780962, 0.01219477, 0.02197256, 0.00364465, 0.        ,\n",
       "        0.00111594, 0.01047836, 0.01456078, 0.        , 0.00410023,\n",
       "        0.00045558, 0.00883404, 0.00136674, 0.01483264, 0.00977112,\n",
       "        0.00045558, 0.00318907, 0.00045558, 0.02642369, 0.00501139,\n",
       "        0.01760925, 0.0022779 , 0.00111594, 0.00428585]),\n",
       " 'rank_test_balanced_accuracy': array([ 2, 39, 25, 61, 40, 36, 61, 22, 79,  4, 13, 79,  1, 44, 16, 41, 61,\n",
       "        30,  8, 61, 61, 61, 61, 27, 11, 21, 53, 47, 55, 55,  6, 12, 61, 84,\n",
       "         9, 17, 41, 61, 79, 35, 14, 53, 55, 61, 47, 33, 51, 61, 61,  5, 49,\n",
       "        19, 26, 20,  7,  3, 61, 61, 61, 61, 23, 29, 10, 44, 61, 55, 33, 24,\n",
       "        61, 41, 55, 31, 51, 27, 32, 79, 46, 79, 15, 36, 18, 49, 55, 36],\n",
       "       dtype=int32),\n",
       " 'split0_train_balanced_accuracy': array([0.84037018, 0.50028474, 0.5       , 0.5       , 0.51395216,\n",
       "        0.5       , 0.5       , 0.5       , 0.50028474, 0.82635077,\n",
       "        0.52534169, 0.5       , 0.8328304 , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.50284738, 0.55125285, 0.50085421,\n",
       "        0.5       , 0.5       , 0.49971526, 0.5       , 0.54498861,\n",
       "        0.5       , 0.5       , 0.5       , 0.50142369, 0.50085421,\n",
       "        0.55170885, 0.52961276, 0.5       , 0.5       , 0.55652628,\n",
       "        0.5       , 0.51224374, 0.5       , 0.5       , 0.5       ,\n",
       "        0.52505695, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50085421, 0.5       , 0.5       , 0.5       , 0.55780182,\n",
       "        0.5       , 0.53530752, 0.5       , 0.52591116, 0.55780182,\n",
       "        0.83796724, 0.5       , 0.50113895, 0.5       , 0.5       ,\n",
       "        0.5       , 0.50170843, 0.55199359, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50142369, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.50911162, 0.5       , 0.5       , 0.5       ,\n",
       "        0.52249431, 0.5       , 0.5022779 , 0.51053531]),\n",
       " 'split1_train_balanced_accuracy': array([0.83006392, 0.50284738, 0.50056948, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.49886105, 0.83898116,\n",
       "        0.5       , 0.5       , 0.83239752, 0.50370159, 0.55410023,\n",
       "        0.5       , 0.5       , 0.5284738 , 0.54986383, 0.50056948,\n",
       "        0.5       , 0.5       , 0.5       , 0.5022779 , 0.51850797,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.55128752, 0.51224374, 0.5       , 0.49886105, 0.55510259,\n",
       "        0.54726651, 0.5       , 0.5       , 0.49914579, 0.5       ,\n",
       "        0.51110478, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.50113895, 0.50142369, 0.5       , 0.5       , 0.80423367,\n",
       "        0.5       , 0.5       , 0.5393632 , 0.5       , 0.55324601,\n",
       "        0.82719343, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.53872437, 0.54788222, 0.5       , 0.49971526,\n",
       "        0.49943052, 0.5       , 0.54299544, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.53530752, 0.5       ,\n",
       "        0.49914579, 0.5       , 0.5       , 0.5       , 0.5059795 ,\n",
       "        0.5       , 0.5       , 0.49943052, 0.50170843]),\n",
       " 'split2_train_balanced_accuracy': array([0.78720717, 0.5       , 0.53103645, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5284738 , 0.5       , 0.82507523,\n",
       "        0.54897494, 0.49971526, 0.82334369, 0.5       , 0.5       ,\n",
       "        0.51110478, 0.5       , 0.50683371, 0.54897494, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.54527335,\n",
       "        0.51224374, 0.50028474, 0.49971526, 0.5       , 0.5       ,\n",
       "        0.55353075, 0.52989749, 0.5       , 0.5       , 0.54271071,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.50170843,\n",
       "        0.51850797, 0.50256264, 0.5       , 0.5       , 0.50113895,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.81243328,\n",
       "        0.50768793, 0.5       , 0.5       , 0.5       , 0.55068337,\n",
       "        0.81553073, 0.5       , 0.49943052, 0.5       , 0.5       ,\n",
       "        0.50142369, 0.5       , 0.55012545, 0.51082005, 0.5       ,\n",
       "        0.50199317, 0.51651481, 0.50683371, 0.5       , 0.51082005,\n",
       "        0.5       , 0.5       , 0.5       , 0.49886105, 0.5       ,\n",
       "        0.5       , 0.5       , 0.49971526, 0.55495444, 0.5       ,\n",
       "        0.51850797, 0.5       , 0.49971526, 0.49886105]),\n",
       " 'split3_train_balanced_accuracy': array([0.83302478, 0.50797267, 0.51281321, 0.5       , 0.5       ,\n",
       "        0.52733485, 0.5       , 0.5       , 0.5       , 0.85016475,\n",
       "        0.51053531, 0.5       , 0.86298742, 0.5       , 0.5464123 ,\n",
       "        0.5       , 0.5       , 0.50170843, 0.53559226, 0.50113895,\n",
       "        0.5       , 0.5       , 0.50085421, 0.50199317, 0.53616173,\n",
       "        0.53160592, 0.50085421, 0.52192483, 0.5       , 0.5       ,\n",
       "        0.86576755, 0.55637813, 0.50085421, 0.5       , 0.54100228,\n",
       "        0.53473804, 0.5       , 0.50170843, 0.49971526, 0.49658314,\n",
       "        0.55552392, 0.5       , 0.5       , 0.50085421, 0.51252847,\n",
       "        0.5       , 0.50028474, 0.5       , 0.5       , 0.85394515,\n",
       "        0.5       , 0.55780182, 0.5       , 0.5       , 0.53929385,\n",
       "        0.83898116, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.54886147, 0.5       , 0.55440808, 0.50085421, 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.51623007, 0.5       , 0.5       , 0.50626424,\n",
       "        0.5       , 0.5       , 0.5       , 0.54157175, 0.5       ,\n",
       "        0.5       , 0.511959  , 0.5       , 0.50085421]),\n",
       " 'split4_train_balanced_accuracy': array([0.84958294, 0.50256264, 0.50028474, 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.51138952, 0.5       , 0.81535157,\n",
       "        0.53103645, 0.5       , 0.84132554, 0.5       , 0.50768793,\n",
       "        0.50028474, 0.5       , 0.50284738, 0.55068337, 0.50056948,\n",
       "        0.5       , 0.5       , 0.5       , 0.52220957, 0.53644647,\n",
       "        0.50711845, 0.50142369, 0.5       , 0.49914579, 0.5       ,\n",
       "        0.55086343, 0.50455581, 0.5       , 0.5       , 0.54441913,\n",
       "        0.51480638, 0.5       , 0.5       , 0.50056948, 0.51309795,\n",
       "        0.51082005, 0.5       , 0.50028474, 0.50028474, 0.5       ,\n",
       "        0.51366743, 0.50028474, 0.5       , 0.5       , 0.83378836,\n",
       "        0.5       , 0.5       , 0.51338269, 0.54726651, 0.55068337,\n",
       "        0.81224457, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.546048  , 0.5       , 0.5       ,\n",
       "        0.50028474, 0.5       , 0.50142369, 0.5       , 0.5       ,\n",
       "        0.5       , 0.51366743, 0.50341686, 0.5       , 0.5179385 ,\n",
       "        0.50085421, 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.54014806, 0.5       , 0.5       , 0.50142369]),\n",
       " 'mean_train_balanced_accuracy': array([0.8280498 , 0.50273349, 0.50894077, 0.5       , 0.50279043,\n",
       "        0.50546697, 0.5       , 0.50797267, 0.49982916, 0.8311847 ,\n",
       "        0.52317768, 0.49994305, 0.83857691, 0.50074032, 0.52164009,\n",
       "        0.5022779 , 0.5       , 0.50854214, 0.54727345, 0.50062642,\n",
       "        0.5       , 0.5       , 0.5001139 , 0.50529613, 0.53627563,\n",
       "        0.51019362, 0.50051253, 0.50432802, 0.5001139 , 0.50017084,\n",
       "        0.61463162, 0.52653759, 0.50017084, 0.49977221, 0.5479522 ,\n",
       "        0.51936219, 0.50244875, 0.50034169, 0.4998861 , 0.5022779 ,\n",
       "        0.52420273, 0.50051253, 0.50005695, 0.50022779, 0.50273349,\n",
       "        0.50313212, 0.50039863, 0.5       , 0.5       , 0.77244045,\n",
       "        0.50153759, 0.51862187, 0.51054918, 0.51463554, 0.55034169,\n",
       "        0.82638343, 0.5       , 0.5001139 , 0.5       , 0.5       ,\n",
       "        0.51005703, 0.50808656, 0.55009147, 0.50233485, 0.49994305,\n",
       "        0.50034169, 0.50330296, 0.51025057, 0.5       , 0.50216401,\n",
       "        0.50028474, 0.5059795 , 0.50068337, 0.50683371, 0.50484055,\n",
       "        0.5       , 0.50182232, 0.49994305, 0.51930524, 0.5011959 ,\n",
       "        0.51623007, 0.5023918 , 0.50028474, 0.50267654]),\n",
       " 'std_train_balanced_accuracy': array([2.15053268e-02, 2.86214849e-03, 1.20677881e-02, 0.00000000e+00,\n",
       "        5.58086560e-03, 1.09339408e-02, 0.00000000e+00, 1.11594066e-02,\n",
       "        4.96457738e-04, 1.21029555e-02, 1.69054804e-02, 1.13895216e-04,\n",
       "        1.34661516e-02, 1.48063781e-03, 2.36582874e-02, 4.41481719e-03,\n",
       "        0.00000000e+00, 1.01168191e-02, 5.89098681e-03, 3.77747698e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.86237471e-04, 8.51095293e-03,\n",
       "        9.72220935e-03, 1.16616132e-02, 5.52127546e-04, 8.79909655e-03,\n",
       "        7.33718606e-04, 3.41685649e-04, 1.25571259e-01, 1.78813676e-02,\n",
       "        3.41685649e-04, 4.55580866e-04, 6.52533751e-03, 1.88976843e-02,\n",
       "        4.89749431e-03, 6.83371298e-04, 4.62644556e-04, 5.66048913e-03,\n",
       "        1.65216779e-02, 1.02505695e-03, 1.13895216e-04, 3.32058764e-04,\n",
       "        4.91731962e-03, 5.28724118e-03, 5.28110393e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.08707457e-01, 3.07517084e-03, 2.38905907e-02,\n",
       "        1.53109885e-02, 1.91547240e-02, 6.10535730e-03, 1.10565108e-02,\n",
       "        0.00000000e+00, 5.57970329e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.94100517e-02, 1.53331898e-02, 2.94899082e-03, 4.25547647e-03,\n",
       "        1.13895216e-04, 8.71130896e-04, 6.60592255e-03, 1.65648053e-02,\n",
       "        0.00000000e+00, 4.32801822e-03, 5.69476082e-04, 7.36806104e-03,\n",
       "        1.36674260e-03, 1.42437341e-02, 6.98392242e-03, 5.40252448e-04,\n",
       "        3.64464692e-03, 1.13895216e-04, 2.40197424e-02, 2.39179954e-03,\n",
       "        1.51217079e-02, 4.78359909e-03, 1.01870978e-03, 4.05329377e-03]),\n",
       " 'split0_test_sensitivity': array([0.77941176, 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.69117647,\n",
       "        1.        , 0.        , 0.80882353, 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.92647059, 1.        , 1.        , 1.        , 0.98529412,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        0.73529412, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.91176471, 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        ]),\n",
       " 'split1_test_sensitivity': array([0.63235294, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.61764706,\n",
       "        0.        , 1.        , 0.75      , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 0.97058824, 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.95588235, 1.        , 0.        , 0.        , 0.98529412,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.57352941,\n",
       "        1.        , 0.        , 0.92647059, 0.        , 1.        ,\n",
       "        0.63235294, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.92647059, 1.        , 0.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ]),\n",
       " 'split2_test_sensitivity': array([0.63235294, 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.70588235,\n",
       "        1.        , 0.        , 0.72058824, 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.98529412, 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.69117647,\n",
       "        1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.70588235, 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.98529412, 1.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_sensitivity': array([0.61764706, 1.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 0.66176471,\n",
       "        1.        , 0.        , 0.79411765, 0.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.66176471, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.69117647,\n",
       "        0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.61764706, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.98529412, 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_test_sensitivity': array([0.68656716, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.53731343,\n",
       "        1.        , 0.        , 0.73134328, 0.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.64179104,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.50746269, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        ]),\n",
       " 'mean_test_sensitivity': array([0.66966637, 0.8       , 0.8       , 0.        , 0.2       ,\n",
       "        0.2       , 0.        , 0.4       , 0.4       , 0.6427568 ,\n",
       "        0.8       , 0.2       , 0.76097454, 0.2       , 0.6       ,\n",
       "        0.8       , 0.        , 1.        , 0.99411765, 1.        ,\n",
       "        0.2       , 0.        , 0.6       , 1.        , 1.        ,\n",
       "        1.        , 0.8       , 0.2       , 0.6       , 0.2       ,\n",
       "        0.90588235, 1.        , 0.6       , 0.6       , 0.99411765,\n",
       "        0.6       , 0.2       , 0.2       , 0.4       , 0.4       ,\n",
       "        1.        , 0.2       , 0.8       , 0.8       , 0.4       ,\n",
       "        0.8       , 1.        , 0.        , 0.        , 0.71953468,\n",
       "        0.6       , 0.4       , 0.38529412, 0.4       , 1.        ,\n",
       "        0.63972783, 0.        , 0.8       , 0.        , 1.        ,\n",
       "        0.39705882, 0.6       , 0.96470588, 1.        , 0.2       ,\n",
       "        0.8       , 1.        , 0.6       , 0.        , 1.        ,\n",
       "        0.2       , 1.        , 1.        , 0.2       , 0.4       ,\n",
       "        0.6       , 0.2       , 0.        , 1.        , 0.6       ,\n",
       "        0.6       , 0.2       , 0.4       , 0.8       ]),\n",
       " 'std_test_sensitivity': array([0.05969972, 0.4       , 0.4       , 0.        , 0.4       ,\n",
       "        0.4       , 0.        , 0.48989795, 0.48989795, 0.06072792,\n",
       "        0.4       , 0.4       , 0.03469149, 0.4       , 0.48989795,\n",
       "        0.4       , 0.        , 0.        , 0.01176471, 0.        ,\n",
       "        0.4       , 0.        , 0.48989795, 0.        , 0.        ,\n",
       "        0.        , 0.4       , 0.4       , 0.48989795, 0.4       ,\n",
       "        0.12464482, 0.        , 0.48989795, 0.48989795, 0.00720438,\n",
       "        0.48989795, 0.4       , 0.4       , 0.48989795, 0.48989795,\n",
       "        0.        , 0.4       , 0.4       , 0.4       , 0.48989795,\n",
       "        0.4       , 0.        , 0.        , 0.        , 0.14671795,\n",
       "        0.48989795, 0.48989795, 0.47245951, 0.48989795, 0.        ,\n",
       "        0.07942966, 0.        , 0.4       , 0.        , 0.        ,\n",
       "        0.48631799, 0.48989795, 0.03789441, 0.        , 0.4       ,\n",
       "        0.4       , 0.        , 0.48989795, 0.        , 0.        ,\n",
       "        0.4       , 0.        , 0.        , 0.4       , 0.48989795,\n",
       "        0.48989795, 0.4       , 0.        , 0.        , 0.48989795,\n",
       "        0.48989795, 0.4       , 0.48989795, 0.4       ]),\n",
       " 'rank_test_sensitivity': array([34, 21, 21, 75, 60, 60, 75, 49, 49, 35, 21, 60, 32, 60, 37, 21, 75,\n",
       "         1, 17,  1, 60, 75, 37,  1,  1,  1, 21, 60, 37, 60, 20,  1, 37, 37,\n",
       "        17, 37, 60, 60, 49, 49,  1, 60, 21, 21, 49, 21,  1, 75, 75, 33, 37,\n",
       "        49, 59, 49,  1, 36, 75, 21, 75,  1, 58, 37, 19,  1, 60, 21,  1, 37,\n",
       "        75,  1, 60,  1,  1, 60, 49, 37, 60, 75,  1, 37, 37, 60, 49, 21],\n",
       "       dtype=int32),\n",
       " 'split0_train_sensitivity': array([0.74907749, 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.70110701,\n",
       "        1.        , 0.        , 0.74538745, 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.98154982, 1.        , 1.        , 1.        , 0.99630996,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        0.73800738, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.98154982, 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        ]),\n",
       " 'split1_train_sensitivity': array([0.69372694, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.72693727,\n",
       "        0.        , 1.        , 0.74907749, 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 0.97785978, 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.97785978, 1.        , 0.        , 0.        , 0.99630996,\n",
       "        1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.64206642,\n",
       "        1.        , 0.        , 0.95571956, 0.        , 1.        ,\n",
       "        0.70848708, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 0.9704797 , 1.        , 0.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ]),\n",
       " 'split2_train_sensitivity': array([0.60516605, 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.69741697,\n",
       "        1.        , 0.        , 0.71217712, 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.67896679,\n",
       "        1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.70110701, 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 1.        , 0.99261993, 1.        , 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_train_sensitivity': array([0.71217712, 1.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 0.76752768,\n",
       "        1.        , 0.        , 0.85239852, 0.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.        ,\n",
       "        0.80442804, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 0.        , 0.80811808,\n",
       "        0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.72693727, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.98154982, 0.        , 0.98523985, 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 1.        ]),\n",
       " 'split4_train_sensitivity': array([0.77205882, 1.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.66544118,\n",
       "        1.        , 0.        , 0.77205882, 0.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.        ,\n",
       "        0.98897059, 1.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.72794118,\n",
       "        1.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.65808824, 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.98161765, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        ]),\n",
       " 'mean_train_sensitivity': array([0.70644129, 0.8       , 0.8       , 0.        , 0.2       ,\n",
       "        0.2       , 0.        , 0.4       , 0.4       , 0.71168602,\n",
       "        0.8       , 0.2       , 0.76621988, 0.2       , 0.6       ,\n",
       "        0.8       , 0.        , 1.        , 0.99557196, 1.        ,\n",
       "        0.2       , 0.        , 0.6       , 1.        , 1.        ,\n",
       "        1.        , 0.8       , 0.2       , 0.6       , 0.2       ,\n",
       "        0.95056165, 1.        , 0.6       , 0.6       , 0.99852399,\n",
       "        0.6       , 0.2       , 0.2       , 0.4       , 0.4       ,\n",
       "        1.        , 0.2       , 0.8       , 0.8       , 0.4       ,\n",
       "        0.8       , 1.        , 0.        , 0.        , 0.77141849,\n",
       "        0.6       , 0.4       , 0.39114391, 0.4       , 1.        ,\n",
       "        0.7065254 , 0.        , 0.8       , 0.        , 1.        ,\n",
       "        0.39630996, 0.6       , 0.98230139, 1.        , 0.2       ,\n",
       "        0.8       , 1.        , 0.6       , 0.        , 1.        ,\n",
       "        0.2       , 1.        , 1.        , 0.2       , 0.4       ,\n",
       "        0.6       , 0.2       , 0.        , 1.        , 0.6       ,\n",
       "        0.6       , 0.2       , 0.4       , 0.8       ]),\n",
       " 'std_train_sensitivity': array([0.05757558, 0.4       , 0.4       , 0.        , 0.4       ,\n",
       "        0.4       , 0.        , 0.48989795, 0.48989795, 0.03407344,\n",
       "        0.4       , 0.4       , 0.04713666, 0.4       , 0.48989795,\n",
       "        0.4       , 0.        , 0.        , 0.00885609, 0.        ,\n",
       "        0.4       , 0.        , 0.48989795, 0.        , 0.        ,\n",
       "        0.        , 0.4       , 0.4       , 0.48989795, 0.4       ,\n",
       "        0.07345731, 0.        , 0.48989795, 0.48989795, 0.00180774,\n",
       "        0.48989795, 0.4       , 0.4       , 0.48989795, 0.48989795,\n",
       "        0.        , 0.4       , 0.4       , 0.4       , 0.48989795,\n",
       "        0.4       , 0.        , 0.        , 0.        , 0.12709518,\n",
       "        0.48989795, 0.48989795, 0.47925611, 0.48989795, 0.        ,\n",
       "        0.02752136, 0.        , 0.4       , 0.        , 0.        ,\n",
       "        0.48541366, 0.48989795, 0.0071539 , 0.        , 0.4       ,\n",
       "        0.4       , 0.        , 0.48989795, 0.        , 0.        ,\n",
       "        0.4       , 0.        , 0.        , 0.4       , 0.48989795,\n",
       "        0.48989795, 0.4       , 0.        , 0.        , 0.48989795,\n",
       "        0.48989795, 0.4       , 0.48989795, 0.4       ]),\n",
       " 'split0_test_specificity': array([0.91799544, 0.        , 1.        , 1.        , 0.02277904,\n",
       "        1.        , 1.        , 1.        , 0.0022779 , 0.9453303 ,\n",
       "        0.04328018, 1.        , 0.90660592, 1.        , 1.        ,\n",
       "        0.        , 1.        , 0.00455581, 0.08883827, 0.        ,\n",
       "        1.        , 1.        , 1.        , 0.        , 0.08200456,\n",
       "        0.        , 1.        , 1.        , 0.0022779 , 0.0022779 ,\n",
       "        0.11161731, 0.05694761, 0.        , 0.        , 0.1070615 ,\n",
       "        1.        , 0.02050114, 1.        , 0.        , 1.        ,\n",
       "        0.04328018, 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.0022779 , 0.        , 1.        , 1.        , 0.10250569,\n",
       "        1.        , 0.06378132, 1.        , 0.04328018, 0.10250569,\n",
       "        0.92255125, 1.        , 0.0022779 , 1.        , 0.        ,\n",
       "        1.        , 0.0022779 , 0.1070615 , 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        0.0022779 , 0.        , 0.        , 1.        , 1.        ,\n",
       "        1.        , 0.01594533, 1.        , 0.        , 1.        ,\n",
       "        0.04100228, 1.        , 0.00455581, 0.02050114]),\n",
       " 'split1_test_specificity': array([0.96810934, 0.01138952, 0.00455581, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99544419, 0.9476082 ,\n",
       "        1.        , 0.        , 0.92482916, 0.01822323, 0.09794989,\n",
       "        0.9977221 , 1.        , 0.04555809, 0.1070615 , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.01138952, 0.04555809,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.10933941, 0.03189066, 1.        , 0.99544419, 0.10250569,\n",
       "        0.08883827, 1.        , 1.        , 0.9977221 , 1.        ,\n",
       "        0.03189066, 1.        , 0.0022779 , 1.        , 1.        ,\n",
       "        0.00911162, 0.00683371, 1.        , 1.        , 0.96810934,\n",
       "        0.        , 1.        , 0.1070615 , 1.        , 0.09794989,\n",
       "        0.95444191, 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.06150342, 0.11161731, 0.        , 1.        ,\n",
       "        0.9977221 , 0.        , 0.07517084, 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.07289294, 1.        ,\n",
       "        0.9977221 , 1.        , 1.        , 0.        , 0.02505695,\n",
       "        1.        , 1.        , 0.9977221 , 0.00683371]),\n",
       " 'split2_test_specificity': array([0.95216401, 1.        , 0.06833713, 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.06378132, 1.        , 0.92482916,\n",
       "        0.11617312, 0.9977221 , 0.92710706, 1.        , 1.        ,\n",
       "        0.02277904, 1.        , 0.00911162, 0.11617312, 0.        ,\n",
       "        0.        , 1.        , 1.        , 0.        , 0.11161731,\n",
       "        0.02733485, 0.0022779 , 0.9977221 , 0.        , 1.        ,\n",
       "        0.11617312, 0.06605923, 0.        , 1.        , 0.10022779,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.00455581,\n",
       "        0.04100228, 0.00455581, 1.        , 0.        , 0.0022779 ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.92710706,\n",
       "        0.01138952, 1.        , 1.        , 1.        , 0.12300683,\n",
       "        0.93394077, 1.        , 0.9977221 , 1.        , 0.        ,\n",
       "        0.00455581, 0.        , 0.12528474, 0.01822323, 1.        ,\n",
       "        0.00455581, 0.0523918 , 0.00911162, 1.        , 0.02050114,\n",
       "        1.        , 0.        , 0.        , 0.99544419, 1.        ,\n",
       "        0.        , 1.        , 0.9977221 , 0.13211845, 0.        ,\n",
       "        0.04100228, 1.        , 1.        , 0.99544419]),\n",
       " 'split3_test_specificity': array([0.9453303 , 0.00911162, 0.01138952, 1.        , 1.        ,\n",
       "        0.02505695, 1.        , 1.        , 0.        , 0.93394077,\n",
       "        0.01138952, 1.        , 0.8428246 , 1.        , 0.07972665,\n",
       "        0.        , 1.        , 0.        , 0.0546697 , 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.        , 0.0546697 ,\n",
       "        0.04555809, 0.        , 0.01594533, 0.        , 1.        ,\n",
       "        0.90888383, 0.09339408, 0.        , 0.        , 0.06605923,\n",
       "        0.0523918 , 1.        , 0.        , 1.        , 0.99544419,\n",
       "        0.09339408, 1.        , 0.        , 0.        , 0.01138952,\n",
       "        1.        , 0.        , 1.        , 1.        , 0.87471526,\n",
       "        1.        , 0.10022779, 1.        , 1.        , 0.06378132,\n",
       "        0.94077449, 1.        , 0.        , 1.        , 0.        ,\n",
       "        0.1047836 , 1.        , 0.10250569, 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.01366743, 0.        , 1.        , 0.00683371,\n",
       "        0.        , 1.        , 1.        , 0.06605923, 0.        ,\n",
       "        1.        , 0.01138952, 0.        , 0.        ]),\n",
       " 'split4_test_specificity': array([0.92027335, 0.0022779 , 0.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.03189066, 1.        , 0.9498861 ,\n",
       "        0.07289294, 1.        , 0.90660592, 1.        , 0.01594533,\n",
       "        0.        , 1.        , 0.0022779 , 0.12072893, 0.        ,\n",
       "        1.        , 1.        , 0.        , 0.05694761, 0.09111617,\n",
       "        0.02733485, 0.0022779 , 1.        , 1.        , 1.        ,\n",
       "        0.13211845, 0.00683371, 1.        , 0.        , 0.10250569,\n",
       "        0.04328018, 1.        , 1.        , 0.        , 0.03189066,\n",
       "        0.02961276, 1.        , 0.        , 0.        , 1.        ,\n",
       "        0.04100228, 0.        , 1.        , 1.        , 0.93166287,\n",
       "        0.        , 1.        , 0.03644647, 0.11161731, 0.12300683,\n",
       "        0.96810934, 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 1.        , 0.13211845, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.0022779 , 1.        , 0.        ,\n",
       "        1.        , 0.04555809, 0.00683371, 1.        , 0.0501139 ,\n",
       "        0.        , 1.        , 1.        , 0.        , 1.        ,\n",
       "        0.09567198, 1.        , 1.        , 0.0022779 ]),\n",
       " 'mean_test_specificity': array([0.94077449, 0.20455581, 0.21685649, 1.        , 0.80455581,\n",
       "        0.80501139, 1.        , 0.6191344 , 0.59954442, 0.94031891,\n",
       "        0.24874715, 0.79954442, 0.90159453, 0.80364465, 0.43872437,\n",
       "        0.20410023, 1.        , 0.01230068, 0.09749431, 0.        ,\n",
       "        0.8       , 1.        , 0.4       , 0.01366743, 0.07699317,\n",
       "        0.02004556, 0.20091116, 0.80273349, 0.40045558, 0.80045558,\n",
       "        0.27562642, 0.05102506, 0.4       , 0.39908884, 0.09567198,\n",
       "        0.43690205, 0.80410023, 0.8       , 0.59954442, 0.60637813,\n",
       "        0.04783599, 0.80091116, 0.20045558, 0.2       , 0.60273349,\n",
       "        0.21047836, 0.00136674, 1.        , 1.        , 0.76082005,\n",
       "        0.4022779 , 0.63280182, 0.62870159, 0.6309795 , 0.10205011,\n",
       "        0.94396355, 1.        , 0.2       , 1.        , 0.        ,\n",
       "        0.62186788, 0.41275626, 0.11571754, 0.00364465, 0.8       ,\n",
       "        0.20045558, 0.01047836, 0.41731207, 1.        , 0.00410023,\n",
       "        0.80045558, 0.0118451 , 0.00136674, 0.81366743, 0.61138952,\n",
       "        0.39954442, 0.80318907, 0.99954442, 0.03963554, 0.40501139,\n",
       "        0.43553531, 0.8022779 , 0.60045558, 0.20501139]),\n",
       " 'std_test_specificity': array([0.01916691, 0.39774427, 0.39234851, 0.        , 0.39088838,\n",
       "        0.38997722, 0.        , 0.4665722 , 0.48859938, 0.00949096,\n",
       "        0.37720995, 0.39977318, 0.03064268, 0.39271071, 0.45908809,\n",
       "        0.39690899, 0.        , 0.01689953, 0.0240381 , 0.        ,\n",
       "        0.4       , 0.        , 0.48989795, 0.0220851 , 0.02412429,\n",
       "        0.01766808, 0.39954572, 0.39339507, 0.48952667, 0.39908884,\n",
       "        0.31672865, 0.0295812 , 0.48989795, 0.48878413, 0.01497192,\n",
       "        0.46002028, 0.39179954, 0.4       , 0.48952667, 0.48030713,\n",
       "        0.02336379, 0.39817768, 0.39977318, 0.4       , 0.48655866,\n",
       "        0.39503511, 0.00273349, 0.        , 0.        , 0.33050186,\n",
       "        0.48805577, 0.44987175, 0.45529376, 0.45247231, 0.02172505,\n",
       "        0.01588665, 0.        , 0.39886202, 0.        , 0.        ,\n",
       "        0.46419867, 0.47998941, 0.01119654, 0.00728929, 0.4       ,\n",
       "        0.39863716, 0.02095672, 0.4764435 , 0.        , 0.00820046,\n",
       "        0.39908884, 0.01766808, 0.00273349, 0.37039145, 0.47614543,\n",
       "        0.48934051, 0.39362187, 0.00091116, 0.05284738, 0.48589232,\n",
       "        0.46131561, 0.39544419, 0.48841286, 0.3952804 ]),\n",
       " 'rank_test_specificity': array([12, 59, 56,  1, 17, 16,  1, 35, 40, 13, 55, 29, 14, 19, 42, 60,  1,\n",
       "        76, 68, 83, 26,  1, 50, 75, 70, 74, 61, 21, 49, 24, 54, 71, 50, 53,\n",
       "        69, 43, 18, 26, 40, 37, 72, 23, 62, 64, 38, 57, 81,  1,  1, 30, 48,\n",
       "        31, 33, 32, 67, 11,  1, 64,  1, 83, 34, 46, 66, 80, 26, 62, 78, 45,\n",
       "         1, 79, 24, 77, 81, 15, 36, 52, 20, 10, 73, 47, 44, 22, 39, 58],\n",
       "       dtype=int32),\n",
       " 'split0_train_specificity': array([9.31662870e-01, 5.69476082e-04, 1.00000000e+00, 1.00000000e+00,\n",
       "        2.79043280e-02, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        5.69476082e-04, 9.51594533e-01, 5.06833713e-02, 1.00000000e+00,\n",
       "        9.20273349e-01, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 5.69476082e-03, 1.02505695e-01, 1.70842825e-03,\n",
       "        1.00000000e+00, 1.00000000e+00, 9.99430524e-01, 0.00000000e+00,\n",
       "        8.99772210e-02, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        2.84738041e-03, 1.70842825e-03, 1.21867882e-01, 5.92255125e-02,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.16742597e-01, 1.00000000e+00,\n",
       "        2.44874715e-02, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        5.01138952e-02, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 1.70842825e-03, 0.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.15603645e-01, 1.00000000e+00, 7.06150342e-02,\n",
       "        1.00000000e+00, 5.18223235e-02, 1.15603645e-01, 9.37927107e-01,\n",
       "        1.00000000e+00, 2.27790433e-03, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 3.41685649e-03, 1.22437358e-01, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 2.84738041e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.82232346e-02, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        4.49886105e-02, 1.00000000e+00, 4.55580866e-03, 2.10706150e-02]),\n",
       " 'split1_train_specificity': array([0.96640091, 0.00569476, 0.00113895, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9977221 , 0.95102506,\n",
       "        1.        , 0.        , 0.91571754, 0.00740319, 0.10820046,\n",
       "        1.        , 1.        , 0.05694761, 0.12186788, 0.00113895,\n",
       "        1.        , 1.        , 0.        , 0.00455581, 0.03701595,\n",
       "        0.        , 0.        , 1.        , 1.        , 1.        ,\n",
       "        0.12471526, 0.02448747, 1.        , 0.9977221 , 0.11389522,\n",
       "        0.09453303, 1.        , 1.        , 0.99829157, 1.        ,\n",
       "        0.02220957, 1.        , 0.        , 1.        , 1.        ,\n",
       "        0.0022779 , 0.00284738, 1.        , 1.        , 0.96640091,\n",
       "        0.        , 1.        , 0.12300683, 1.        , 0.10649203,\n",
       "        0.94589977, 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.07744875, 0.12528474, 0.        , 0.99943052,\n",
       "        0.99886105, 0.        , 0.08599089, 1.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 0.07061503, 1.        ,\n",
       "        0.99829157, 1.        , 1.        , 0.        , 0.011959  ,\n",
       "        1.        , 1.        , 0.99886105, 0.00341686]),\n",
       " 'split2_train_specificity': array([9.69248292e-01, 1.00000000e+00, 6.20728929e-02, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 5.69476082e-02,\n",
       "        1.00000000e+00, 9.52733485e-01, 9.79498861e-02, 9.99430524e-01,\n",
       "        9.34510251e-01, 1.00000000e+00, 1.00000000e+00, 2.22095672e-02,\n",
       "        1.00000000e+00, 1.36674260e-02, 9.79498861e-02, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        9.05466970e-02, 2.44874715e-02, 5.69476082e-04, 9.99430524e-01,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.07061503e-01, 5.97949886e-02,\n",
       "        0.00000000e+00, 1.00000000e+00, 8.54214123e-02, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 3.41685649e-03,\n",
       "        3.70159453e-02, 5.12528474e-03, 1.00000000e+00, 0.00000000e+00,\n",
       "        2.27790433e-03, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 9.45899772e-01, 1.53758542e-02, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.01366743e-01, 9.29954442e-01,\n",
       "        1.00000000e+00, 9.98861048e-01, 1.00000000e+00, 0.00000000e+00,\n",
       "        2.84738041e-03, 0.00000000e+00, 1.07630979e-01, 2.16400911e-02,\n",
       "        1.00000000e+00, 3.98633257e-03, 3.30296128e-02, 1.36674260e-02,\n",
       "        1.00000000e+00, 2.16400911e-02, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 9.97722096e-01, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 9.99430524e-01, 1.09908884e-01, 0.00000000e+00,\n",
       "        3.70159453e-02, 1.00000000e+00, 9.99430524e-01, 9.97722096e-01]),\n",
       " 'split3_train_specificity': array([9.53872437e-01, 1.59453303e-02, 2.56264237e-02, 1.00000000e+00,\n",
       "        1.00000000e+00, 5.46697039e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 9.32801822e-01, 2.10706150e-02, 1.00000000e+00,\n",
       "        8.73576310e-01, 1.00000000e+00, 9.28246014e-02, 0.00000000e+00,\n",
       "        1.00000000e+00, 3.41685649e-03, 7.11845103e-02, 2.27790433e-03,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.70842825e-03, 3.98633257e-03,\n",
       "        7.23234624e-02, 6.32118451e-02, 1.70842825e-03, 4.38496583e-02,\n",
       "        0.00000000e+00, 1.00000000e+00, 9.27107062e-01, 1.12756264e-01,\n",
       "        1.70842825e-03, 0.00000000e+00, 8.20045558e-02, 6.94760820e-02,\n",
       "        1.00000000e+00, 3.41685649e-03, 9.99430524e-01, 9.93166287e-01,\n",
       "        1.11047836e-01, 1.00000000e+00, 0.00000000e+00, 1.70842825e-03,\n",
       "        2.50569476e-02, 1.00000000e+00, 5.69476082e-04, 1.00000000e+00,\n",
       "        1.00000000e+00, 8.99772210e-01, 1.00000000e+00, 1.15603645e-01,\n",
       "        1.00000000e+00, 1.00000000e+00, 7.85876993e-02, 9.51025057e-01,\n",
       "        1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.16173121e-01, 1.00000000e+00, 1.23576310e-01, 1.70842825e-03,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.24601367e-02,\n",
       "        0.00000000e+00, 1.00000000e+00, 1.25284738e-02, 0.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 8.31435080e-02, 0.00000000e+00,\n",
       "        1.00000000e+00, 2.39179954e-02, 0.00000000e+00, 1.70842825e-03]),\n",
       " 'split4_train_specificity': array([9.27107062e-01, 5.12528474e-03, 5.69476082e-04, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.27790433e-02,\n",
       "        1.00000000e+00, 9.65261959e-01, 6.20728929e-02, 1.00000000e+00,\n",
       "        9.10592255e-01, 1.00000000e+00, 1.53758542e-02, 5.69476082e-04,\n",
       "        1.00000000e+00, 5.69476082e-03, 1.01366743e-01, 1.13895216e-03,\n",
       "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.44191344e-02,\n",
       "        7.28929385e-02, 1.42369021e-02, 2.84738041e-03, 1.00000000e+00,\n",
       "        9.98291572e-01, 1.00000000e+00, 1.12756264e-01, 9.11161731e-03,\n",
       "        1.00000000e+00, 0.00000000e+00, 8.88382688e-02, 2.96127563e-02,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.13895216e-03, 2.61958998e-02,\n",
       "        2.16400911e-02, 1.00000000e+00, 5.69476082e-04, 5.69476082e-04,\n",
       "        1.00000000e+00, 2.73348519e-02, 5.69476082e-04, 1.00000000e+00,\n",
       "        1.00000000e+00, 9.39635535e-01, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.67653759e-02, 9.45330296e-02, 1.01366743e-01, 9.66400911e-01,\n",
       "        1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.10478360e-01, 0.00000000e+00,\n",
       "        0.00000000e+00, 5.69476082e-04, 0.00000000e+00, 2.84738041e-03,\n",
       "        1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.73348519e-02,\n",
       "        6.83371298e-03, 1.00000000e+00, 3.58769932e-02, 1.70842825e-03,\n",
       "        1.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        8.02961276e-02, 1.00000000e+00, 1.00000000e+00, 2.84738041e-03]),\n",
       " 'mean_train_specificity': array([9.49658314e-01, 2.05466970e-01, 2.17881549e-01, 1.00000000e+00,\n",
       "        8.05580866e-01, 8.10933941e-01, 1.00000000e+00, 6.15945330e-01,\n",
       "        5.99658314e-01, 9.50683371e-01, 2.46355353e-01, 7.99886105e-01,\n",
       "        9.10933941e-01, 8.01480638e-01, 4.43280182e-01, 2.04555809e-01,\n",
       "        1.00000000e+00, 1.70842825e-02, 9.89749431e-02, 1.25284738e-03,\n",
       "        8.00000000e-01, 1.00000000e+00, 4.00227790e-01, 1.05922551e-02,\n",
       "        7.25512528e-02, 2.03872437e-02, 2.01025057e-01, 8.08656036e-01,\n",
       "        4.00227790e-01, 8.00341686e-01, 2.78701595e-01, 5.30751708e-02,\n",
       "        4.00341686e-01, 3.99544419e-01, 9.73804100e-02, 4.38724374e-01,\n",
       "        8.04897494e-01, 8.00683371e-01, 5.99772210e-01, 6.04555809e-01,\n",
       "        4.84054670e-02, 8.01025057e-01, 2.00113895e-01, 2.00455581e-01,\n",
       "        6.05466970e-01, 2.06264237e-01, 7.97266515e-04, 1.00000000e+00,\n",
       "        1.00000000e+00, 7.73462415e-01, 4.03075171e-01, 6.37243736e-01,\n",
       "        6.29954442e-01, 6.29271071e-01, 1.00683371e-01, 9.46241458e-01,\n",
       "        1.00000000e+00, 2.00227790e-01, 1.00000000e+00, 0.00000000e+00,\n",
       "        6.23804100e-01, 4.16173121e-01, 1.17881549e-01, 4.66970387e-03,\n",
       "        7.99886105e-01, 2.00683371e-01, 6.60592255e-03, 4.20501139e-01,\n",
       "        1.00000000e+00, 4.32801822e-03, 8.00569476e-01, 1.19589977e-02,\n",
       "        1.36674260e-03, 8.13667426e-01, 6.09681093e-01, 4.00000000e-01,\n",
       "        8.03644647e-01, 9.99886105e-01, 3.86104784e-02, 4.02391800e-01,\n",
       "        4.32460137e-01, 8.04783599e-01, 6.00569476e-01, 2.05353075e-01]),\n",
       " 'std_train_specificity': array([1.74025033e-02, 3.97298351e-01, 3.91701297e-01, 0.00000000e+00,\n",
       "        3.88838269e-01, 3.78132118e-01, 0.00000000e+00, 4.70493074e-01,\n",
       "        4.89387216e-01, 1.03675932e-02, 3.77625529e-01, 3.99943113e-01,\n",
       "        2.03059552e-02, 3.97038724e-01, 4.55647575e-01, 3.97813573e-01,\n",
       "        0.00000000e+00, 2.02336383e-02, 1.62211741e-02, 7.55495396e-04,\n",
       "        4.00000000e-01, 0.00000000e+00, 4.89479901e-01, 1.70219059e-02,\n",
       "        1.94444187e-02, 2.33232265e-02, 3.99488669e-01, 3.82403253e-01,\n",
       "        4.89015899e-01, 3.99316629e-01, 3.24264222e-01, 3.57627352e-02,\n",
       "        4.89619361e-01, 4.89340508e-01, 1.48326384e-02, 4.58747197e-01,\n",
       "        3.90205011e-01, 3.98633257e-01, 4.89247425e-01, 4.81588734e-01,\n",
       "        3.30433559e-02, 3.97949886e-01, 3.99943113e-01, 3.99772696e-01,\n",
       "        4.83255994e-01, 3.96996379e-01, 1.05622079e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 3.29637904e-01, 4.87419419e-01, 4.44511595e-01,\n",
       "        4.54232115e-01, 4.54249193e-01, 1.22107146e-02, 1.23595991e-02,\n",
       "        0.00000000e+00, 3.99317603e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.62135591e-01, 4.77495477e-01, 7.31948474e-03, 8.51095293e-03,\n",
       "        3.99943113e-01, 3.99091601e-01, 1.32118451e-02, 4.74021793e-01,\n",
       "        0.00000000e+00, 8.65603645e-03, 3.98861048e-01, 1.47361221e-02,\n",
       "        2.73348519e-03, 3.71527243e-01, 4.78098095e-01, 4.89201182e-01,\n",
       "        3.92710706e-01, 2.27790433e-04, 4.80394847e-02, 4.87964592e-01,\n",
       "        4.63623290e-01, 3.90432802e-01, 4.88505280e-01, 3.96249069e-01])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3eeb1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__activation': 'logistic',\n",
       " 'classifier__alpha': 0.8773407884629941,\n",
       " 'classifier__early_stopping': True,\n",
       " 'classifier__hidden_layer_sizes': (150, 150),\n",
       " 'classifier__learning_rate': 'adaptive',\n",
       " 'classifier__learning_rate_init': 0.0023019050769459534}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfa19c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/04/28 14:29:12 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"8c2da395658847e2b4c7ba6114ef8d60\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22120 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Successfully registered model 'mlp_randomizedsearch'.\n",
      "Created version '1' of model 'mlp_randomizedsearch'.\n"
     ]
    }
   ],
   "source": [
    "# Convertimos los resultados de la validación cruzada en un dataframe\n",
    "df_results = pd.DataFrame(random_search.cv_results_)\n",
    "df_results\n",
    "\n",
    "# Filtrando la fila con condiciones específicas\n",
    "filtered_row = df_results.loc[\n",
    "    (df_results['param_classifier__activation'] == 'logistic') &\n",
    "    (df_results['param_classifier__alpha'] == 0.8773407884629941) &\n",
    "    (df_results['param_classifier__early_stopping'] == True) &\n",
    "    (df_results['param_classifier__hidden_layer_sizes'] == (150, 150)) &\n",
    "    (df_results['param_classifier__learning_rate'] == 'adaptive') &\n",
    "    (df_results['param_classifier__learning_rate_init'] == 0.0023019050769459534)\n",
    "]\n",
    "\n",
    "index_row = filtered_row.index[0]\n",
    "\n",
    "# Registro los resultados en MLFlow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Almaceno los valores de los hiperparámetros\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    # Registra las métricas de cada fold para cada métrica\n",
    "    for metric in METRICS.keys():\n",
    "        \n",
    "        # Media\n",
    "        mlflow.log_metric(f\"mean_train_{metric}\", df_results[f\"mean_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"mean_test_{metric}\", df_results[f\"mean_test_{metric}\"][index_row])\n",
    "\n",
    "        # Desviación típica\n",
    "        mlflow.log_metric(f\"std_train_{metric}\", df_results[f\"std_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"std_test_{metric}\", df_results[f\"std_test_{metric}\"][index_row])\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            # Resultados de entrenamiento en cada fold\n",
    "            mlflow.log_metric(f\"train_{metric}fold{i}\", df_results[f\"split{i}_train_{metric}\"][index_row])\n",
    "            # Resultados de validación en cada fold\n",
    "            mlflow.log_metric(f\"test_{metric}fold{i}\", df_results[f\"split{i}_test_{metric}\"][index_row])\n",
    "\n",
    "    # Establece una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"RandomizedSearch 84 combinaciones. sinfic\")\n",
    "\n",
    "    # Infiere el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    signature = infer_signature(X_scaled_train, random_search.best_estimator_.predict(X_scaled_train))\n",
    "\n",
    "    # Registra el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=random_search,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_scaled_train,\n",
    "        registered_model_name=\"mlp_randomizedsearch\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea95abe",
   "metadata": {},
   "source": [
    "### 3. Ajuste combinado de hiperparámetros\n",
    "Vamos a intentar aplicar las estrategias de búsqueda a todos los hiperparámetros a la vez para ver si mejora el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e6046",
   "metadata": {},
   "source": [
    "### 3.1 Grid Search\n",
    "[GridSearchCV - Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "440ec744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    }
   ],
   "source": [
    "# Definir los hiperparámetros a ajustar (135)\n",
    "# Dejamos solo las opciones de arquitectura que eran las más prometedoras en la prueba individual (2 capas)\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100, 100), (150, 150), (200, 100)],\n",
    "    'classifier__activation': ['logistic'],\n",
    "    'classifier__early_stopping': [True],\n",
    "    'classifier__alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1],\n",
    "    'classifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'classifier__learning_rate_init': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Inicializo GridSearch\n",
    "grid_search3 = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=kf,\n",
    "                           scoring=METRICS, return_train_score=True,\n",
    "                           refit='balanced_accuracy',\n",
    "                           verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search3.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "# Resultados\n",
    "cv_results_gr3 = grid_search3.cv_results_\n",
    "best_params_gr3 = grid_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d5d0782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__activation': 'logistic',\n",
       " 'classifier__alpha': 1,\n",
       " 'classifier__early_stopping': True,\n",
       " 'classifier__hidden_layer_sizes': (150, 150),\n",
       " 'classifier__learning_rate': 'constant',\n",
       " 'classifier__learning_rate_init': 0.001}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_gr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b0d6aba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/04/28 14:29:43 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"f061c4093a9e4983a8e1f57fef6bf831\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22120 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Registered model 'mlp_gridsearch' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'mlp_gridsearch'.\n"
     ]
    }
   ],
   "source": [
    "# Convertimos los resultados de la validación cruzada en un dataframe\n",
    "df_results = pd.DataFrame(grid_search3.cv_results_)\n",
    "df_results\n",
    "\n",
    "# Filtrando la fila con condiciones específicas\n",
    "filtered_row = df_results.loc[\n",
    "    (df_results['param_classifier__activation'] == 'logistic') &\n",
    "    (df_results['param_classifier__alpha'] == 1) &\n",
    "    (df_results['param_classifier__early_stopping'] == True) &\n",
    "    (df_results['param_classifier__hidden_layer_sizes'] == (150, 150)) &\n",
    "    (df_results['param_classifier__learning_rate'] == 'constant') &\n",
    "    (df_results['param_classifier__learning_rate_init'] == 0.001)\n",
    "]\n",
    "\n",
    "index_row = filtered_row.index[0]\n",
    "\n",
    "# Registro los resultados en MLFlow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Almaceno los valores de los hiperparámetros\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    # Registra las métricas de cada fold para cada métrica\n",
    "    for metric in METRICS.keys():\n",
    "        \n",
    "        # Media\n",
    "        mlflow.log_metric(f\"mean_train_{metric}\", df_results[f\"mean_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"mean_test_{metric}\", df_results[f\"mean_test_{metric}\"][index_row])\n",
    "\n",
    "        # Desviación típica\n",
    "        mlflow.log_metric(f\"std_train_{metric}\", df_results[f\"std_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"std_test_{metric}\", df_results[f\"std_test_{metric}\"][index_row])\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            # Resultados de entrenamiento en cada fold\n",
    "            mlflow.log_metric(f\"train_{metric}fold{i}\", df_results[f\"split{i}_train_{metric}\"][index_row])\n",
    "            # Resultados de validación en cada fold\n",
    "            mlflow.log_metric(f\"test_{metric}fold{i}\", df_results[f\"split{i}_test_{metric}\"][index_row])\n",
    "\n",
    "    # Establece una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"GridSearch 135 combinaciones. sinfic\")\n",
    "\n",
    "    # Infiere el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    signature = infer_signature(X_scaled_train, grid_search.best_estimator_.predict(X_scaled_train))\n",
    "\n",
    "    # Registra el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=grid_search,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_scaled_train,\n",
    "        registered_model_name=\"mlp_gridsearch\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc9793",
   "metadata": {},
   "source": [
    "### 3.2 Random Search\n",
    "[RandomizedSearchCV - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9bf4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    }
   ],
   "source": [
    "# Defino las distribuciones de los parámetros\n",
    "param_grid = {\n",
    "    'classifier__hidden_layer_sizes': [(100, 100), (150, 150), (200, 100)],\n",
    "    'classifier__activation': ['logistic'],\n",
    "    'classifier__early_stopping': [True],\n",
    "    'classifier__alpha': uniform(0.00001, 1),\n",
    "    'classifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'classifier__learning_rate_init': uniform(0.0001, 0.1)\n",
    "}\n",
    "\n",
    "# Inicializo RandomizedSearch\n",
    "N_ITER = 135\n",
    "random_search3 = RandomizedSearchCV(estimator=pipeline, param_distributions=param_dist, n_iter=N_ITER, cv=kf,\n",
    "                                    scoring=METRICS, return_train_score=True,\n",
    "                                    refit=\"balanced_accuracy\",\n",
    "                                    verbose=1, n_jobs=-1)\n",
    "\n",
    "random_search3.fit(X_scaled_train, y_scaled_train)\n",
    "\n",
    "# Resultados\n",
    "cv_results_rand3 = random_search3.cv_results_\n",
    "best_params_rand3 = random_search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "420a29a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__activation': 'logistic',\n",
       " 'classifier__alpha': 0.18324441181200563,\n",
       " 'classifier__early_stopping': True,\n",
       " 'classifier__hidden_layer_sizes': (150, 150),\n",
       " 'classifier__learning_rate': 'adaptive',\n",
       " 'classifier__learning_rate_init': 0.0001757617926269938}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_rand3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53113442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/anaconda3/lib/python3.11/site-packages/mlflow/types/utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/04/28 14:31:05 WARNING mlflow.utils.validation: Tag value '[{\"run_id\": \"fa7b7d4033574571996229ad87aceb64\", \"artifact_path\": \"mlp_model\", \"utc_time_created\": \"2...' (22120 characters) is truncated to 5000 characters to meet the length limit.\n",
      "Registered model 'mlp_randomizedsearch' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'mlp_randomizedsearch'.\n"
     ]
    }
   ],
   "source": [
    "# Convertimos los resultados de la validación cruzada en un dataframe\n",
    "df_results = pd.DataFrame(random_search3.cv_results_)\n",
    "df_results\n",
    "\n",
    "# Filtrando la fila con condiciones específicas\n",
    "filtered_row = df_results.loc[\n",
    "    (df_results['param_classifier__activation'] == 'logistic') &\n",
    "    (df_results['param_classifier__alpha'] == 0.18324441181200563) &\n",
    "    (df_results['param_classifier__early_stopping'] == True) &\n",
    "    (df_results['param_classifier__hidden_layer_sizes'] == (150, 150)) &\n",
    "    (df_results['param_classifier__learning_rate'] == 'adaptive') &\n",
    "    (df_results['param_classifier__learning_rate_init'] == 0.0001757617926269938)\n",
    "]\n",
    "\n",
    "index_row = filtered_row.index[0]\n",
    "\n",
    "# Registro los resultados en MLFlow\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Almaceno los valores de los hiperparámetros\n",
    "    for key, value in best_params.items():\n",
    "        mlflow.log_param(key, value)\n",
    "\n",
    "    # Registra las métricas de cada fold para cada métrica\n",
    "    for metric in METRICS.keys():\n",
    "        \n",
    "        # Media\n",
    "        mlflow.log_metric(f\"mean_train_{metric}\", df_results[f\"mean_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"mean_test_{metric}\", df_results[f\"mean_test_{metric}\"][index_row])\n",
    "\n",
    "        # Desviación típica\n",
    "        mlflow.log_metric(f\"std_train_{metric}\", df_results[f\"std_train_{metric}\"][index_row])\n",
    "        mlflow.log_metric(f\"std_test_{metric}\", df_results[f\"std_test_{metric}\"][index_row])\n",
    "\n",
    "        for i in range(5):\n",
    "\n",
    "            # Resultados de entrenamiento en cada fold\n",
    "            mlflow.log_metric(f\"train_{metric}fold{i}\", df_results[f\"split{i}_train_{metric}\"][index_row])\n",
    "            # Resultados de validación en cada fold\n",
    "            mlflow.log_metric(f\"test_{metric}fold{i}\", df_results[f\"split{i}_test_{metric}\"][index_row])\n",
    "\n",
    "    # Establece una etiqueta que describe el propósito de esta ejecución\n",
    "    mlflow.set_tag(\"Información\", \"RandomizedSearch 135 combinaciones. sinfic\")\n",
    "\n",
    "    # Infiere el signature del modelo, que describe el tipo de entrada y salida del modelo\n",
    "    signature = infer_signature(X_scaled_train, random_search.best_estimator_.predict(X_scaled_train))\n",
    "\n",
    "    # Registra el modelo\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=random_search,\n",
    "        artifact_path=\"mlp_model\",\n",
    "        signature=signature,\n",
    "        input_example=X_scaled_train,\n",
    "        registered_model_name=\"mlp_randomizedsearch\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecabe64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
